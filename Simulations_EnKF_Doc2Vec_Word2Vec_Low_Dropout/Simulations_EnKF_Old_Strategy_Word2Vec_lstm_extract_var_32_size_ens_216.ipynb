{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7e77ba-f153-483a-9899-ec020da8bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Low_Dropout//low_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Low_Dropout//low_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833\n",
      "Trainable params: 833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = doc2vec_dbow.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =32\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 8\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    # train_lstm = catch1[idx][3].numpy()\n",
    "    # valid_lstm = catch1[idx][4].numpy()\n",
    "    # # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    # test_lstm = catch1[idx][5].numpy()\n",
    "    \n",
    "    train_doc2vec = []\n",
    "    for seq in catch[idx][0]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        train_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    train_doc2vec = np.array(train_doc2vec)\n",
    "    \n",
    "    valid_doc2vec = []\n",
    "    for seq in catch[idx][1]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        valid_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    valid_doc2vec = np.array(valid_doc2vec)\n",
    "    \n",
    "    test_doc2vec = []\n",
    "    for seq in catch[idx][2]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        test_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    test_doc2vec = np.array(test_doc2vec)        \n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_word2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_word2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_word2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_word2vec, valid_word2vec))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_word2vec, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_doc2vec.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 0.875,\n",
       " 0.9278781566251849,\n",
       " 0.8692255434641964,\n",
       " 0.9650438633413558,\n",
       " 6,\n",
       " 0.31666666666666665,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9eeee4d-565c-423e-bfa9-b4b4f7135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   26.2s\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   30.7s\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   54.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:   58.1s remaining:   49.5s\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  1.2min remaining:   38.0s\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  1.4min remaining:   23.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  1.4min remaining:    9.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829378/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7798ea51-ba04-4dcd-9b51-4812a5ea82e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.981478</td>\n",
       "      <td>0.984743</td>\n",
       "      <td>0.941485</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.730643</td>\n",
       "      <td>0.847856</td>\n",
       "      <td>0.981452</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.815420</td>\n",
       "      <td>0.802909</td>\n",
       "      <td>0.989568</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.883468</td>\n",
       "      <td>0.840355</td>\n",
       "      <td>0.988250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.786868</td>\n",
       "      <td>0.686898</td>\n",
       "      <td>0.978768</td>\n",
       "      <td>13</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.860262</td>\n",
       "      <td>0.782828</td>\n",
       "      <td>0.972748</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.943513</td>\n",
       "      <td>0.925936</td>\n",
       "      <td>0.980420</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.898623</td>\n",
       "      <td>0.978615</td>\n",
       "      <td>11</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.885984</td>\n",
       "      <td>0.922685</td>\n",
       "      <td>0.983474</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.894246</td>\n",
       "      <td>0.975857</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.937177</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>0.987702</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.959566</td>\n",
       "      <td>0.930283</td>\n",
       "      <td>0.983330</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.983916</td>\n",
       "      <td>0.986785</td>\n",
       "      <td>0.986632</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.710324</td>\n",
       "      <td>0.717083</td>\n",
       "      <td>0.979219</td>\n",
       "      <td>14</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.830087</td>\n",
       "      <td>0.620951</td>\n",
       "      <td>0.981602</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.889715</td>\n",
       "      <td>0.847874</td>\n",
       "      <td>0.983015</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.942676</td>\n",
       "      <td>0.885869</td>\n",
       "      <td>0.977581</td>\n",
       "      <td>8</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.738364</td>\n",
       "      <td>0.674565</td>\n",
       "      <td>0.958797</td>\n",
       "      <td>8</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.815137</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>13</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.928724</td>\n",
       "      <td>0.971881</td>\n",
       "      <td>8</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.773080</td>\n",
       "      <td>0.774691</td>\n",
       "      <td>0.983046</td>\n",
       "      <td>11</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.905847</td>\n",
       "      <td>0.919772</td>\n",
       "      <td>0.967968</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978514</td>\n",
       "      <td>0.960573</td>\n",
       "      <td>0.978222</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.773093</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>0.978387</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.886149</td>\n",
       "      <td>0.876390</td>\n",
       "      <td>0.986017</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.702152</td>\n",
       "      <td>0.730804</td>\n",
       "      <td>0.980492</td>\n",
       "      <td>13</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.805074</td>\n",
       "      <td>0.703492</td>\n",
       "      <td>0.987963</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.800517</td>\n",
       "      <td>0.771546</td>\n",
       "      <td>0.987670</td>\n",
       "      <td>13</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823070</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.872957</td>\n",
       "      <td>0.883794</td>\n",
       "      <td>0.982704</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.935160</td>\n",
       "      <td>0.893394</td>\n",
       "      <td>0.988503</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.855031</td>\n",
       "      <td>0.726431</td>\n",
       "      <td>0.976552</td>\n",
       "      <td>7</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.972506</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.987388</td>\n",
       "      <td>6</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.897542</td>\n",
       "      <td>0.932885</td>\n",
       "      <td>0.981580</td>\n",
       "      <td>11</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.808155</td>\n",
       "      <td>0.760353</td>\n",
       "      <td>0.979984</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.841651</td>\n",
       "      <td>0.716221</td>\n",
       "      <td>0.970441</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.799885</td>\n",
       "      <td>0.868173</td>\n",
       "      <td>0.970106</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.969937</td>\n",
       "      <td>0.973031</td>\n",
       "      <td>0.977196</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.834531</td>\n",
       "      <td>0.840527</td>\n",
       "      <td>0.975062</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.854897</td>\n",
       "      <td>0.853393</td>\n",
       "      <td>0.980780</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.917864</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.985275</td>\n",
       "      <td>12</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.841753</td>\n",
       "      <td>0.803546</td>\n",
       "      <td>0.981338</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795545</td>\n",
       "      <td>0.852095</td>\n",
       "      <td>0.979111</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.862448</td>\n",
       "      <td>0.946169</td>\n",
       "      <td>0.979994</td>\n",
       "      <td>9</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.847557</td>\n",
       "      <td>0.933328</td>\n",
       "      <td>0.969739</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.821452</td>\n",
       "      <td>0.817675</td>\n",
       "      <td>0.975641</td>\n",
       "      <td>9</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.945632</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>0.965175</td>\n",
       "      <td>5</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.927561</td>\n",
       "      <td>0.914347</td>\n",
       "      <td>0.976493</td>\n",
       "      <td>9</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.942912</td>\n",
       "      <td>0.981208</td>\n",
       "      <td>11</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.926124</td>\n",
       "      <td>0.927047</td>\n",
       "      <td>0.977285</td>\n",
       "      <td>10</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         1.000000          1.000            0.981478           0.984743   \n",
       "1         0.984848          1.000            0.730643           0.847856   \n",
       "2         0.969697          1.000            0.815420           0.802909   \n",
       "3         1.000000          1.000            0.883468           0.840355   \n",
       "4         0.954545          1.000            0.786868           0.686898   \n",
       "5         0.954545          1.000            0.860262           0.782828   \n",
       "6         0.984848          1.000            0.943513           0.925936   \n",
       "7         1.000000          1.000            0.878000           0.898623   \n",
       "8         0.984848          1.000            0.885984           0.922685   \n",
       "9         1.000000          1.000            0.936306           0.894246   \n",
       "10        1.000000          1.000            0.937177           0.919561   \n",
       "11        1.000000          0.875            0.959566           0.930283   \n",
       "12        1.000000          1.000            0.983916           0.986785   \n",
       "13        0.954545          1.000            0.710324           0.717083   \n",
       "14        0.984848          0.875            0.830087           0.620951   \n",
       "15        1.000000          1.000            0.889715           0.847874   \n",
       "16        1.000000          1.000            0.942676           0.885869   \n",
       "17        1.000000          0.875            0.738364           0.674565   \n",
       "18        0.954545          1.000            0.790554           0.815137   \n",
       "19        0.984848          0.875            0.892752           0.928724   \n",
       "20        0.954545          1.000            0.773080           0.774691   \n",
       "21        1.000000          1.000            0.905847           0.919772   \n",
       "22        1.000000          1.000            0.978514           0.960573   \n",
       "23        0.984848          0.875            0.773093           0.820865   \n",
       "24        0.954545          1.000            0.886149           0.876390   \n",
       "25        0.969697          0.625            0.702152           0.730804   \n",
       "26        0.969697          0.875            0.805074           0.703492   \n",
       "27        0.984848          0.875            0.800517           0.771546   \n",
       "28        1.000000          1.000            0.999992           1.000000   \n",
       "29        0.954545          0.875            0.872957           0.883794   \n",
       "30        0.984848          0.875            0.935160           0.893394   \n",
       "31        1.000000          0.875            0.855031           0.726431   \n",
       "32        1.000000          1.000            0.972506           0.983591   \n",
       "33        0.969697          0.875            0.897542           0.932885   \n",
       "34        1.000000          1.000            0.808155           0.760353   \n",
       "35        0.984848          0.750            0.841651           0.716221   \n",
       "36        0.969697          1.000            0.799885           0.868173   \n",
       "37        0.969697          1.000            0.969937           0.973031   \n",
       "38        0.969697          1.000            0.834531           0.840527   \n",
       "39        0.954545          1.000            0.854897           0.853393   \n",
       "40        1.000000          0.625            0.917864           0.817619   \n",
       "41        0.969697          1.000            0.841753           0.803546   \n",
       "42        1.000000          1.000            0.795545           0.852095   \n",
       "43        0.984848          1.000            0.862448           0.946169   \n",
       "44        0.969697          1.000            0.847557           0.933328   \n",
       "45        0.984848          1.000            0.821452           0.817675   \n",
       "46        1.000000          1.000            0.945632           0.959645   \n",
       "47        1.000000          1.000            0.927561           0.914347   \n",
       "48        0.984848          1.000            0.906055           0.942912   \n",
       "49        1.000000          1.000            0.926124           0.927047   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.941485          6    0.316667  \n",
       "1          0.981452         10    0.333333  \n",
       "2          0.989568         11    0.366667  \n",
       "3          0.988250          9    0.300000  \n",
       "4          0.978768         13    0.400000  \n",
       "5          0.972748          7    0.316667  \n",
       "6          0.980420          9    0.350000  \n",
       "7          0.978615         11    0.350000  \n",
       "8          0.983474          9    0.350000  \n",
       "9          0.975857          9    0.350000  \n",
       "10         0.987702          8    0.333333  \n",
       "11         0.983330         11    0.366667  \n",
       "12         0.986632          9    0.350000  \n",
       "13         0.979219         14    0.416667  \n",
       "14         0.981602         10    0.366667  \n",
       "15         0.983015          9    0.333333  \n",
       "16         0.977581          8    0.316667  \n",
       "17         0.958797          8    0.316667  \n",
       "18         0.983381         13    0.316667  \n",
       "19         0.971881          8    0.350000  \n",
       "20         0.983046         11    0.383333  \n",
       "21         0.967968          7    0.333333  \n",
       "22         0.978222          8    0.333333  \n",
       "23         0.978387          6    0.316667  \n",
       "24         0.986017         10    0.366667  \n",
       "25         0.980492         13    0.350000  \n",
       "26         0.987963         10    0.366667  \n",
       "27         0.987670         13    0.383333  \n",
       "28         0.823070          4    0.283333  \n",
       "29         0.982704         11    0.366667  \n",
       "30         0.988503         10    0.333333  \n",
       "31         0.976552          7    0.266667  \n",
       "32         0.987388          6    0.300000  \n",
       "33         0.981580         11    0.383333  \n",
       "34         0.979984         10    0.366667  \n",
       "35         0.970441          8    0.333333  \n",
       "36         0.970106          9    0.350000  \n",
       "37         0.977196         11    0.366667  \n",
       "38         0.975062         10    0.366667  \n",
       "39         0.980780         10    0.350000  \n",
       "40         0.985275         12    0.316667  \n",
       "41         0.981338         10    0.350000  \n",
       "42         0.979111         10    0.350000  \n",
       "43         0.979994          9    0.300000  \n",
       "44         0.969739         10    0.333333  \n",
       "45         0.975641          9    0.266667  \n",
       "46         0.965175          5    0.283333  \n",
       "47         0.976493          9    0.266667  \n",
       "48         0.981208         11    0.283333  \n",
       "49         0.977285         10    0.283333  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.868715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.856364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.975563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>9.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>0.336667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics     value\n",
       "0      train_coverage  0.983636\n",
       "1       test_coverage  0.952500\n",
       "2  avg_ci_width_train  0.868715\n",
       "3   avg_ci_width_test  0.856364\n",
       "4     avg_lstm_weight  0.975563\n",
       "5           exit_iter  9.440000\n",
       "6          time_taken  0.336667"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
