{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7e77ba-f153-483a-9899-ec020da8bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Low_Dropout//low_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Low_Dropout//low_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833\n",
      "Trainable params: 833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = doc2vec_dbow.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =16\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 8\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    # train_lstm = catch1[idx][3].numpy()\n",
    "    # valid_lstm = catch1[idx][4].numpy()\n",
    "    # # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    # test_lstm = catch1[idx][5].numpy()\n",
    "    \n",
    "    train_doc2vec = []\n",
    "    for seq in catch[idx][0]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        train_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    train_doc2vec = np.array(train_doc2vec)\n",
    "    \n",
    "    valid_doc2vec = []\n",
    "    for seq in catch[idx][1]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        valid_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    valid_doc2vec = np.array(valid_doc2vec)\n",
    "    \n",
    "    test_doc2vec = []\n",
    "    for seq in catch[idx][2]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        test_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    test_doc2vec = np.array(test_doc2vec)        \n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_word2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_word2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_word2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_word2vec, valid_word2vec))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_word2vec, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_doc2vec.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 1.0,\n",
       " 0.999502303436302,\n",
       " 0.9998838150454412,\n",
       " 0.8382262790370832,\n",
       " 4,\n",
       " 0.3333333333333333,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9eeee4d-565c-423e-bfa9-b4b4f7135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   23.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   30.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   50.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:   56.8s remaining:   48.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  1.1min remaining:   34.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  1.3min remaining:   22.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  1.4min remaining:    9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1356356/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7798ea51-ba04-4dcd-9b51-4812a5ea82e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.885612</td>\n",
       "      <td>0.797436</td>\n",
       "      <td>0.879055</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.831909</td>\n",
       "      <td>0.970699</td>\n",
       "      <td>8</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.719180</td>\n",
       "      <td>0.700487</td>\n",
       "      <td>0.972984</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.747173</td>\n",
       "      <td>0.602105</td>\n",
       "      <td>0.962863</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.911372</td>\n",
       "      <td>0.898402</td>\n",
       "      <td>0.966080</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.989738</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>0.756315</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.839251</td>\n",
       "      <td>0.956374</td>\n",
       "      <td>8</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795484</td>\n",
       "      <td>0.813973</td>\n",
       "      <td>0.968751</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.637321</td>\n",
       "      <td>0.569910</td>\n",
       "      <td>0.969976</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.891005</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>0.968659</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.826606</td>\n",
       "      <td>0.799802</td>\n",
       "      <td>0.975381</td>\n",
       "      <td>9</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.932657</td>\n",
       "      <td>0.918252</td>\n",
       "      <td>0.967336</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.953015</td>\n",
       "      <td>0.978520</td>\n",
       "      <td>0.959638</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.767018</td>\n",
       "      <td>0.972512</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.974569</td>\n",
       "      <td>0.877533</td>\n",
       "      <td>0.921653</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.841018</td>\n",
       "      <td>0.769351</td>\n",
       "      <td>0.978082</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.812810</td>\n",
       "      <td>0.738263</td>\n",
       "      <td>0.969788</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.652476</td>\n",
       "      <td>0.639509</td>\n",
       "      <td>0.950701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.901302</td>\n",
       "      <td>0.921338</td>\n",
       "      <td>0.980885</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.974650</td>\n",
       "      <td>0.943468</td>\n",
       "      <td>0.947762</td>\n",
       "      <td>5</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.735856</td>\n",
       "      <td>0.773644</td>\n",
       "      <td>0.968124</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.706523</td>\n",
       "      <td>0.816364</td>\n",
       "      <td>0.844839</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.968594</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.948546</td>\n",
       "      <td>0.978110</td>\n",
       "      <td>0.651104</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.841211</td>\n",
       "      <td>0.872488</td>\n",
       "      <td>0.971144</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.642357</td>\n",
       "      <td>0.707487</td>\n",
       "      <td>0.966333</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.901484</td>\n",
       "      <td>0.878501</td>\n",
       "      <td>0.983600</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.783700</td>\n",
       "      <td>0.815755</td>\n",
       "      <td>0.968957</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.879746</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.929441</td>\n",
       "      <td>0.897977</td>\n",
       "      <td>0.900950</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.939453</td>\n",
       "      <td>0.927832</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>9</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.953121</td>\n",
       "      <td>0.848660</td>\n",
       "      <td>0.680276</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.947189</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.975376</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.929576</td>\n",
       "      <td>0.945427</td>\n",
       "      <td>0.955251</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.957078</td>\n",
       "      <td>0.908431</td>\n",
       "      <td>0.911979</td>\n",
       "      <td>6</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.675872</td>\n",
       "      <td>0.668231</td>\n",
       "      <td>0.980220</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.768610</td>\n",
       "      <td>0.560968</td>\n",
       "      <td>0.957864</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994804</td>\n",
       "      <td>0.995740</td>\n",
       "      <td>0.943733</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.820179</td>\n",
       "      <td>0.775179</td>\n",
       "      <td>0.954065</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.942624</td>\n",
       "      <td>0.969385</td>\n",
       "      <td>0.955481</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.780821</td>\n",
       "      <td>0.699170</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.937384</td>\n",
       "      <td>0.899341</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.929970</td>\n",
       "      <td>0.958543</td>\n",
       "      <td>0.948853</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.749412</td>\n",
       "      <td>0.933109</td>\n",
       "      <td>0.955992</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.937484</td>\n",
       "      <td>0.930633</td>\n",
       "      <td>0.956312</td>\n",
       "      <td>6</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.864088</td>\n",
       "      <td>0.761077</td>\n",
       "      <td>0.952670</td>\n",
       "      <td>6</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866737</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.845668</td>\n",
       "      <td>0.851705</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>8</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.868766</td>\n",
       "      <td>0.850365</td>\n",
       "      <td>0.954434</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.733100</td>\n",
       "      <td>0.970712</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         0.984848          1.000            0.885612           0.797436   \n",
       "1         0.969697          0.875            0.802453           0.831909   \n",
       "2         0.954545          1.000            0.719180           0.700487   \n",
       "3         0.984848          1.000            0.747173           0.602105   \n",
       "4         1.000000          1.000            0.911372           0.898402   \n",
       "5         1.000000          1.000            0.989738           0.999835   \n",
       "6         0.954545          1.000            0.891673           0.839251   \n",
       "7         0.984848          1.000            0.795484           0.813973   \n",
       "8         0.969697          1.000            0.637321           0.569910   \n",
       "9         1.000000          1.000            0.891005           0.843362   \n",
       "10        0.984848          1.000            0.826606           0.799802   \n",
       "11        1.000000          0.875            0.932657           0.918252   \n",
       "12        1.000000          1.000            0.953015           0.978520   \n",
       "13        1.000000          1.000            0.787698           0.767018   \n",
       "14        1.000000          1.000            0.974569           0.877533   \n",
       "15        0.954545          0.875            0.841018           0.769351   \n",
       "16        0.984848          1.000            0.812810           0.738263   \n",
       "17        0.984848          1.000            0.652476           0.639509   \n",
       "18        1.000000          1.000            0.901302           0.921338   \n",
       "19        1.000000          1.000            0.974650           0.943468   \n",
       "20        0.969697          1.000            0.735856           0.773644   \n",
       "21        0.969697          0.875            0.706523           0.816364   \n",
       "22        1.000000          1.000            0.999783           0.999856   \n",
       "23        1.000000          1.000            0.948546           0.978110   \n",
       "24        1.000000          1.000            0.841211           0.872488   \n",
       "25        0.954545          0.750            0.642357           0.707487   \n",
       "26        1.000000          1.000            0.901484           0.878501   \n",
       "27        0.984848          0.875            0.783700           0.815755   \n",
       "28        1.000000          1.000            0.999545           0.999872   \n",
       "29        1.000000          1.000            0.929441           0.897977   \n",
       "30        0.969697          1.000            0.939453           0.927832   \n",
       "31        1.000000          1.000            0.953121           0.848660   \n",
       "32        0.984848          1.000            0.947189           0.966438   \n",
       "33        1.000000          1.000            0.929576           0.945427   \n",
       "34        1.000000          1.000            0.957078           0.908431   \n",
       "35        0.954545          1.000            0.675872           0.668231   \n",
       "36        1.000000          0.875            0.768610           0.560968   \n",
       "37        1.000000          1.000            0.994804           0.995740   \n",
       "38        0.984848          1.000            0.820179           0.775179   \n",
       "39        1.000000          1.000            0.942624           0.969385   \n",
       "40        0.969697          0.625            0.780821           0.699170   \n",
       "41        0.984848          0.750            0.937384           0.899341   \n",
       "42        1.000000          1.000            0.929970           0.958543   \n",
       "43        0.954545          1.000            0.749412           0.933109   \n",
       "44        1.000000          1.000            0.937484           0.930633   \n",
       "45        1.000000          0.875            0.864088           0.761077   \n",
       "46        1.000000          1.000            1.000000           1.000000   \n",
       "47        0.984848          1.000            0.845668           0.851705   \n",
       "48        0.984848          1.000            0.868766           0.850365   \n",
       "49        0.984848          1.000            0.641975           0.733100   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.879055          5    0.300000  \n",
       "1          0.970699          8    0.283333  \n",
       "2          0.972984         10    0.366667  \n",
       "3          0.962863          7    0.316667  \n",
       "4          0.966080          8    0.333333  \n",
       "5          0.756315          5    0.300000  \n",
       "6          0.956374          8    0.350000  \n",
       "7          0.968751         10    0.366667  \n",
       "8          0.969976         10    0.350000  \n",
       "9          0.968659          8    0.266667  \n",
       "10         0.975381          9    0.300000  \n",
       "11         0.967336         10    0.300000  \n",
       "12         0.959638          8    0.333333  \n",
       "13         0.972512         12    0.383333  \n",
       "14         0.921653          5    0.300000  \n",
       "15         0.978082         11    0.366667  \n",
       "16         0.969788          7    0.250000  \n",
       "17         0.950701          5    0.233333  \n",
       "18         0.980885          8    0.266667  \n",
       "19         0.947762          5    0.283333  \n",
       "20         0.968124          7    0.333333  \n",
       "21         0.844839          6    0.316667  \n",
       "22         0.968594          6    0.316667  \n",
       "23         0.651104          8    0.333333  \n",
       "24         0.971144          9    0.350000  \n",
       "25         0.966333         12    0.383333  \n",
       "26         0.983600          7    0.316667  \n",
       "27         0.968957          9    0.350000  \n",
       "28         0.879746          4    0.283333  \n",
       "29         0.900950          7    0.316667  \n",
       "30         0.963397          9    0.300000  \n",
       "31         0.680276          4    0.283333  \n",
       "32         0.975376         10    0.300000  \n",
       "33         0.955251          7    0.250000  \n",
       "34         0.911979          6    0.266667  \n",
       "35         0.980220         11    0.366667  \n",
       "36         0.957864          5    0.300000  \n",
       "37         0.943733          8    0.333333  \n",
       "38         0.954065          5    0.300000  \n",
       "39         0.955481          6    0.316667  \n",
       "40         0.975799          9    0.333333  \n",
       "41         0.960784          7    0.316667  \n",
       "42         0.948853          7    0.316667  \n",
       "43         0.955992          5    0.300000  \n",
       "44         0.956312          6    0.300000  \n",
       "45         0.952670          6    0.266667  \n",
       "46         0.866737          3    0.250000  \n",
       "47         0.969925          8    0.300000  \n",
       "48         0.954434          8    0.266667  \n",
       "49         0.970712          8    0.266667  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.986970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.858007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.843462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.937775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>7.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>0.309667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics     value\n",
       "0      train_coverage  0.986970\n",
       "1       test_coverage  0.965000\n",
       "2  avg_ci_width_train  0.858007\n",
       "3   avg_ci_width_test  0.843462\n",
       "4     avg_lstm_weight  0.937775\n",
       "5           exit_iter  7.440000\n",
       "6          time_taken  0.309667"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
