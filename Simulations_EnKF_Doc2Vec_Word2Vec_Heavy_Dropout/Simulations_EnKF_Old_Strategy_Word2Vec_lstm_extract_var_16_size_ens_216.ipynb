{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3d7e77ba-f153-483a-9899-ec020da8bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                816       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833\n",
      "Trainable params: 833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = doc2vec_dbow.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =16\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 8\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    # train_lstm = catch1[idx][3].numpy()\n",
    "    # valid_lstm = catch1[idx][4].numpy()\n",
    "    # # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    # test_lstm = catch1[idx][5].numpy()\n",
    "    \n",
    "    train_doc2vec = []\n",
    "    for seq in catch[idx][0]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        train_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    train_doc2vec = np.array(train_doc2vec)\n",
    "    \n",
    "    valid_doc2vec = []\n",
    "    for seq in catch[idx][1]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        valid_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    valid_doc2vec = np.array(valid_doc2vec)\n",
    "    \n",
    "    test_doc2vec = []\n",
    "    for seq in catch[idx][2]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        test_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    test_doc2vec = np.array(test_doc2vec)        \n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_word2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_word2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_word2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_word2vec, valid_word2vec))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_word2vec, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_doc2vec.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 1.0,\n",
       " 0.8234088699323789,\n",
       " 0.8406320391731997,\n",
       " 0.9551335404018909,\n",
       " 5,\n",
       " 0.31666666666666665,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c9eeee4d-565c-423e-bfa9-b4b4f7135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   22.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   53.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:   58.7s remaining:   50.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  1.0min remaining:   31.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  1.3min remaining:   22.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  1.4min remaining:    9.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1354867/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "7798ea51-ba04-4dcd-9b51-4812a5ea82e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>0.930262</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.682209</td>\n",
       "      <td>0.688925</td>\n",
       "      <td>0.977061</td>\n",
       "      <td>11</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900001</td>\n",
       "      <td>0.967736</td>\n",
       "      <td>0.969255</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.953354</td>\n",
       "      <td>0.942765</td>\n",
       "      <td>0.944864</td>\n",
       "      <td>8</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.874006</td>\n",
       "      <td>0.693987</td>\n",
       "      <td>0.966326</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>0.966964</td>\n",
       "      <td>0.805014</td>\n",
       "      <td>5</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.834363</td>\n",
       "      <td>0.719924</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>11</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.683129</td>\n",
       "      <td>0.706073</td>\n",
       "      <td>0.967185</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.756652</td>\n",
       "      <td>0.721695</td>\n",
       "      <td>0.954549</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.698411</td>\n",
       "      <td>0.581928</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.746440</td>\n",
       "      <td>0.769608</td>\n",
       "      <td>0.961841</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.862466</td>\n",
       "      <td>0.913952</td>\n",
       "      <td>0.953108</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.936890</td>\n",
       "      <td>0.934530</td>\n",
       "      <td>0.948513</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.822786</td>\n",
       "      <td>0.738198</td>\n",
       "      <td>0.906970</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.769749</td>\n",
       "      <td>0.724325</td>\n",
       "      <td>0.729366</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978442</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.953455</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>0.892629</td>\n",
       "      <td>0.964619</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.949330</td>\n",
       "      <td>0.972378</td>\n",
       "      <td>0.636017</td>\n",
       "      <td>5</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.950001</td>\n",
       "      <td>0.629551</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.773189</td>\n",
       "      <td>0.487240</td>\n",
       "      <td>0.909456</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918079</td>\n",
       "      <td>0.864443</td>\n",
       "      <td>0.971239</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.722294</td>\n",
       "      <td>0.708600</td>\n",
       "      <td>0.973378</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.702366</td>\n",
       "      <td>0.664852</td>\n",
       "      <td>0.973261</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.681254</td>\n",
       "      <td>0.713169</td>\n",
       "      <td>0.979314</td>\n",
       "      <td>14</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.909619</td>\n",
       "      <td>0.910141</td>\n",
       "      <td>0.962071</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.757788</td>\n",
       "      <td>0.937415</td>\n",
       "      <td>0.953758</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.839154</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.946469</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.727069</td>\n",
       "      <td>0.981146</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.865556</td>\n",
       "      <td>0.875130</td>\n",
       "      <td>0.965207</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.783668</td>\n",
       "      <td>0.826287</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.877454</td>\n",
       "      <td>0.876910</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>10</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.710664</td>\n",
       "      <td>0.668756</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>8</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.912242</td>\n",
       "      <td>0.904288</td>\n",
       "      <td>0.974595</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.690492</td>\n",
       "      <td>0.708447</td>\n",
       "      <td>0.942627</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.756633</td>\n",
       "      <td>0.810622</td>\n",
       "      <td>0.967779</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.923886</td>\n",
       "      <td>0.877289</td>\n",
       "      <td>0.803377</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.812206</td>\n",
       "      <td>0.885497</td>\n",
       "      <td>0.948672</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.840305</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>0.963059</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.907237</td>\n",
       "      <td>0.974950</td>\n",
       "      <td>0.845742</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.985179</td>\n",
       "      <td>0.992620</td>\n",
       "      <td>0.968407</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.984585</td>\n",
       "      <td>0.994618</td>\n",
       "      <td>0.924753</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.907983</td>\n",
       "      <td>0.879710</td>\n",
       "      <td>0.975009</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.927787</td>\n",
       "      <td>0.944714</td>\n",
       "      <td>0.806324</td>\n",
       "      <td>6</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.976969</td>\n",
       "      <td>0.979926</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>5</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.767474</td>\n",
       "      <td>0.824049</td>\n",
       "      <td>0.687204</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.878280</td>\n",
       "      <td>0.869131</td>\n",
       "      <td>0.938344</td>\n",
       "      <td>8</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.707925</td>\n",
       "      <td>0.713031</td>\n",
       "      <td>0.959292</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.854679</td>\n",
       "      <td>0.876260</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>7</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.746545</td>\n",
       "      <td>0.827945</td>\n",
       "      <td>0.962602</td>\n",
       "      <td>11</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.742127</td>\n",
       "      <td>0.774090</td>\n",
       "      <td>0.954302</td>\n",
       "      <td>8</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         1.000000          1.000            0.997881           0.996525   \n",
       "1         0.969697          0.875            0.682209           0.688925   \n",
       "2         1.000000          1.000            0.900001           0.967736   \n",
       "3         1.000000          1.000            0.953354           0.942765   \n",
       "4         0.984848          0.875            0.874006           0.693987   \n",
       "5         1.000000          1.000            0.920807           0.966964   \n",
       "6         0.969697          0.750            0.834363           0.719924   \n",
       "7         0.984848          0.875            0.683129           0.706073   \n",
       "8         1.000000          1.000            0.756652           0.721695   \n",
       "9         1.000000          0.875            0.662110           0.698411   \n",
       "10        1.000000          1.000            0.746440           0.769608   \n",
       "11        0.984848          1.000            0.862466           0.913952   \n",
       "12        1.000000          1.000            0.936890           0.934530   \n",
       "13        1.000000          0.875            0.822786           0.738198   \n",
       "14        1.000000          1.000            0.769749           0.724325   \n",
       "15        1.000000          1.000            0.978442           0.988439   \n",
       "16        1.000000          1.000            0.893429           0.892629   \n",
       "17        1.000000          1.000            0.949330           0.972378   \n",
       "18        1.000000          1.000            0.908898           0.950001   \n",
       "19        0.969697          1.000            0.773189           0.487240   \n",
       "20        1.000000          1.000            0.918079           0.864443   \n",
       "21        0.969697          1.000            0.722294           0.708600   \n",
       "22        0.984848          0.875            0.702366           0.664852   \n",
       "23        0.954545          1.000            0.681254           0.713169   \n",
       "24        1.000000          1.000            0.909619           0.910141   \n",
       "25        1.000000          0.875            0.757788           0.937415   \n",
       "26        1.000000          1.000            0.839154           0.848333   \n",
       "27        0.969697          1.000            0.708417           0.727069   \n",
       "28        1.000000          1.000            0.865556           0.875130   \n",
       "29        1.000000          1.000            0.783668           0.826287   \n",
       "30        0.954545          1.000            0.877454           0.876910   \n",
       "31        1.000000          1.000            0.710664           0.668756   \n",
       "32        1.000000          0.875            0.912242           0.904288   \n",
       "33        0.969697          0.875            0.690492           0.708447   \n",
       "34        0.984848          0.875            0.756633           0.810622   \n",
       "35        0.969697          0.875            0.923886           0.877289   \n",
       "36        0.969697          0.875            0.812206           0.885497   \n",
       "37        0.984848          0.875            0.840305           0.785606   \n",
       "38        1.000000          1.000            0.907237           0.974950   \n",
       "39        1.000000          1.000            0.985179           0.992620   \n",
       "40        0.984848          1.000            0.984585           0.994618   \n",
       "41        1.000000          1.000            0.907983           0.879710   \n",
       "42        1.000000          1.000            0.927787           0.944714   \n",
       "43        1.000000          1.000            0.976969           0.979926   \n",
       "44        1.000000          1.000            0.767474           0.824049   \n",
       "45        1.000000          1.000            0.878280           0.869131   \n",
       "46        1.000000          1.000            0.707925           0.713031   \n",
       "47        0.969697          1.000            0.854679           0.876260   \n",
       "48        0.954545          1.000            0.746545           0.827945   \n",
       "49        1.000000          1.000            0.742127           0.774090   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.930262          5    0.300000  \n",
       "1          0.977061         11    0.383333  \n",
       "2          0.969255          6    0.316667  \n",
       "3          0.944864          8    0.283333  \n",
       "4          0.966326          7    0.333333  \n",
       "5          0.805014          5    0.233333  \n",
       "6          0.970067         11    0.283333  \n",
       "7          0.967185          9    0.350000  \n",
       "8          0.954549          9    0.350000  \n",
       "9          0.581928          6    0.316667  \n",
       "10         0.961841          7    0.250000  \n",
       "11         0.953108          8    0.333333  \n",
       "12         0.948513          8    0.333333  \n",
       "13         0.906970          7    0.316667  \n",
       "14         0.729366          6    0.316667  \n",
       "15         0.953455          7    0.250000  \n",
       "16         0.964619          8    0.266667  \n",
       "17         0.636017          5    0.233333  \n",
       "18         0.629551          6    0.250000  \n",
       "19         0.909456          6    0.316667  \n",
       "20         0.971239          5    0.300000  \n",
       "21         0.973378          8    0.333333  \n",
       "22         0.973261          8    0.333333  \n",
       "23         0.979314         14    0.416667  \n",
       "24         0.962071          7    0.316667  \n",
       "25         0.953758          7    0.333333  \n",
       "26         0.946469          6    0.316667  \n",
       "27         0.981146         12    0.383333  \n",
       "28         0.965207          9    0.350000  \n",
       "29         0.971910          7    0.333333  \n",
       "30         0.984514         10    0.283333  \n",
       "31         0.970516          8    0.283333  \n",
       "32         0.974595          7    0.250000  \n",
       "33         0.942627          8    0.266667  \n",
       "34         0.967779          7    0.333333  \n",
       "35         0.803377          4    0.300000  \n",
       "36         0.948672          6    0.316667  \n",
       "37         0.963059          7    0.316667  \n",
       "38         0.845742          6    0.316667  \n",
       "39         0.968407          5    0.300000  \n",
       "40         0.924753          5    0.300000  \n",
       "41         0.975009          8    0.333333  \n",
       "42         0.806324          6    0.300000  \n",
       "43         0.904165          5    0.233333  \n",
       "44         0.687204          6    0.250000  \n",
       "45         0.938344          8    0.316667  \n",
       "46         0.959292          8    0.333333  \n",
       "47         0.960452          7    0.266667  \n",
       "48         0.962602         11    0.283333  \n",
       "49         0.954302          8    0.283333  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.989697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.834100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.834364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.915578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>7.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>0.306000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics     value\n",
       "0      train_coverage  0.989697\n",
       "1       test_coverage  0.962500\n",
       "2  avg_ci_width_train  0.834100\n",
       "3   avg_ci_width_test  0.834364\n",
       "4     avg_lstm_weight  0.915578\n",
       "5           exit_iter  7.360000\n",
       "6          time_taken  0.306000"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
