{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7e77ba-f153-483a-9899-ec020da8bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833\n",
      "Trainable params: 833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = doc2vec_dbow.dv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =32\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 8\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    # train_lstm = catch1[idx][3].numpy()\n",
    "    # valid_lstm = catch1[idx][4].numpy()\n",
    "    # # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    # test_lstm = catch1[idx][5].numpy()\n",
    "    \n",
    "    train_doc2vec = []\n",
    "    for seq in catch[idx][0]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        train_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    train_doc2vec = np.array(train_doc2vec)\n",
    "    \n",
    "    valid_doc2vec = []\n",
    "    for seq in catch[idx][1]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        valid_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    valid_doc2vec = np.array(valid_doc2vec)\n",
    "    \n",
    "    test_doc2vec = []\n",
    "    for seq in catch[idx][2]:\n",
    "        seq_txt = seq[0]\n",
    "        seq_split = seq_txt.split(\" \")\n",
    "        test_doc2vec.append(doc2vec_dbow.infer_vector(seq_split))\n",
    "    test_doc2vec = np.array(test_doc2vec)        \n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_word2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_word2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_word2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_word2vec, valid_word2vec))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_word2vec, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_doc2vec.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 1.0,\n",
       " 0.9248809048083125,\n",
       " 0.8624288060437639,\n",
       " 0.9790241725754713,\n",
       " 8,\n",
       " 0.31666666666666665,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9eeee4d-565c-423e-bfa9-b4b4f7135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   24.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   32.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   55.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  1.0min remaining:   51.7s\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  1.1min remaining:   34.1s\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  1.4min remaining:   23.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/2467791455.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  1.5min remaining:    9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827864/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7798ea51-ba04-4dcd-9b51-4812a5ea82e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.806889</td>\n",
       "      <td>0.798114</td>\n",
       "      <td>0.971974</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.835388</td>\n",
       "      <td>0.797822</td>\n",
       "      <td>0.985514</td>\n",
       "      <td>12</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842459</td>\n",
       "      <td>0.941144</td>\n",
       "      <td>0.971200</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.847068</td>\n",
       "      <td>0.824332</td>\n",
       "      <td>0.972215</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.791559</td>\n",
       "      <td>0.609647</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>14</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.789751</td>\n",
       "      <td>0.705744</td>\n",
       "      <td>0.986642</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.847172</td>\n",
       "      <td>0.714893</td>\n",
       "      <td>0.982345</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.817365</td>\n",
       "      <td>0.825779</td>\n",
       "      <td>0.979622</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.719230</td>\n",
       "      <td>0.798299</td>\n",
       "      <td>0.973791</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.881607</td>\n",
       "      <td>0.822323</td>\n",
       "      <td>0.968361</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.811170</td>\n",
       "      <td>0.722741</td>\n",
       "      <td>0.972164</td>\n",
       "      <td>8</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.782976</td>\n",
       "      <td>0.796129</td>\n",
       "      <td>0.985015</td>\n",
       "      <td>14</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.967588</td>\n",
       "      <td>0.939629</td>\n",
       "      <td>0.985648</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.982902</td>\n",
       "      <td>11</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.828657</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>0.985405</td>\n",
       "      <td>9</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.940773</td>\n",
       "      <td>0.942834</td>\n",
       "      <td>0.982381</td>\n",
       "      <td>14</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.939355</td>\n",
       "      <td>0.959663</td>\n",
       "      <td>0.966665</td>\n",
       "      <td>9</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.716161</td>\n",
       "      <td>0.643131</td>\n",
       "      <td>0.972929</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.897948</td>\n",
       "      <td>0.987155</td>\n",
       "      <td>0.967688</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.942941</td>\n",
       "      <td>0.985026</td>\n",
       "      <td>0.982695</td>\n",
       "      <td>10</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.817208</td>\n",
       "      <td>0.836229</td>\n",
       "      <td>0.982224</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.888283</td>\n",
       "      <td>0.983472</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.865966</td>\n",
       "      <td>0.900350</td>\n",
       "      <td>0.980290</td>\n",
       "      <td>11</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.768422</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.985141</td>\n",
       "      <td>13</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.903362</td>\n",
       "      <td>0.931055</td>\n",
       "      <td>0.977462</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.756240</td>\n",
       "      <td>0.898223</td>\n",
       "      <td>0.970915</td>\n",
       "      <td>8</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.907749</td>\n",
       "      <td>0.968540</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.982410</td>\n",
       "      <td>14</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.692739</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>14</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.646004</td>\n",
       "      <td>0.670863</td>\n",
       "      <td>0.971993</td>\n",
       "      <td>12</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.850521</td>\n",
       "      <td>0.905464</td>\n",
       "      <td>0.982676</td>\n",
       "      <td>13</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.929483</td>\n",
       "      <td>0.872402</td>\n",
       "      <td>0.972961</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.860406</td>\n",
       "      <td>0.929497</td>\n",
       "      <td>0.986605</td>\n",
       "      <td>12</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.745497</td>\n",
       "      <td>0.748434</td>\n",
       "      <td>0.984223</td>\n",
       "      <td>12</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777529</td>\n",
       "      <td>0.686496</td>\n",
       "      <td>0.987789</td>\n",
       "      <td>13</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.736513</td>\n",
       "      <td>0.660284</td>\n",
       "      <td>0.970854</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.832634</td>\n",
       "      <td>0.866818</td>\n",
       "      <td>0.978062</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.938345</td>\n",
       "      <td>0.931114</td>\n",
       "      <td>0.978996</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.920308</td>\n",
       "      <td>0.941383</td>\n",
       "      <td>0.982701</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.844063</td>\n",
       "      <td>0.862600</td>\n",
       "      <td>0.979278</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998177</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.983319</td>\n",
       "      <td>6</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.974751</td>\n",
       "      <td>0.928625</td>\n",
       "      <td>0.977669</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.893363</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.980372</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.855459</td>\n",
       "      <td>0.954962</td>\n",
       "      <td>0.987153</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.745647</td>\n",
       "      <td>0.828842</td>\n",
       "      <td>0.967668</td>\n",
       "      <td>15</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.662050</td>\n",
       "      <td>0.622242</td>\n",
       "      <td>0.983518</td>\n",
       "      <td>12</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.701148</td>\n",
       "      <td>0.732697</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>13</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.928433</td>\n",
       "      <td>0.933222</td>\n",
       "      <td>0.980120</td>\n",
       "      <td>8</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.815837</td>\n",
       "      <td>0.827475</td>\n",
       "      <td>0.978167</td>\n",
       "      <td>10</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.659549</td>\n",
       "      <td>0.675072</td>\n",
       "      <td>0.975834</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         0.969697          1.000            0.806889           0.798114   \n",
       "1         0.969697          1.000            0.835388           0.797822   \n",
       "2         1.000000          1.000            0.842459           0.941144   \n",
       "3         0.969697          1.000            0.847068           0.824332   \n",
       "4         1.000000          0.750            0.791559           0.609647   \n",
       "5         0.969697          1.000            0.789751           0.705744   \n",
       "6         0.984848          0.875            0.847172           0.714893   \n",
       "7         1.000000          1.000            0.817365           0.825779   \n",
       "8         0.969697          1.000            0.719230           0.798299   \n",
       "9         1.000000          1.000            0.881607           0.822323   \n",
       "10        0.969697          1.000            0.811170           0.722741   \n",
       "11        0.954545          0.625            0.782976           0.796129   \n",
       "12        1.000000          1.000            0.967588           0.939629   \n",
       "13        0.954545          0.875            0.814826           0.906055   \n",
       "14        0.954545          0.875            0.828657           0.750115   \n",
       "15        1.000000          1.000            0.940773           0.942834   \n",
       "16        0.969697          1.000            0.939355           0.959663   \n",
       "17        0.954545          0.875            0.716161           0.643131   \n",
       "18        0.984848          1.000            0.897948           0.987155   \n",
       "19        1.000000          1.000            0.942941           0.985026   \n",
       "20        0.984848          1.000            0.817208           0.836229   \n",
       "21        1.000000          1.000            0.888283           0.983472   \n",
       "22        0.984848          0.875            0.865966           0.900350   \n",
       "23        0.984848          1.000            0.768422           0.804938   \n",
       "24        0.969697          1.000            0.903362           0.931055   \n",
       "25        0.969697          0.875            0.756240           0.898223   \n",
       "26        1.000000          1.000            0.937853           0.907749   \n",
       "27        0.984848          1.000            0.815399           0.848404   \n",
       "28        0.954545          0.875            0.792780           0.692739   \n",
       "29        0.984848          1.000            0.646004           0.670863   \n",
       "30        0.984848          1.000            0.850521           0.905464   \n",
       "31        1.000000          1.000            0.929483           0.872402   \n",
       "32        0.969697          1.000            0.860406           0.929497   \n",
       "33        0.969697          0.875            0.745497           0.748434   \n",
       "34        0.969697          0.750            0.777529           0.686496   \n",
       "35        0.969697          0.875            0.736513           0.660284   \n",
       "36        0.984848          1.000            0.832634           0.866818   \n",
       "37        1.000000          1.000            0.938345           0.931114   \n",
       "38        1.000000          1.000            0.920308           0.941383   \n",
       "39        0.984848          0.875            0.844063           0.862600   \n",
       "40        1.000000          1.000            0.998177           0.998973   \n",
       "41        1.000000          1.000            0.974751           0.928625   \n",
       "42        0.969697          1.000            0.893363           0.920896   \n",
       "43        0.954545          1.000            0.855459           0.954962   \n",
       "44        0.969697          0.750            0.745647           0.828842   \n",
       "45        0.954545          0.875            0.662050           0.622242   \n",
       "46        0.969697          0.875            0.701148           0.732697   \n",
       "47        0.984848          1.000            0.928433           0.933222   \n",
       "48        0.969697          0.875            0.815837           0.827475   \n",
       "49        0.954545          0.875            0.659549           0.675072   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.971974          7    0.333333  \n",
       "1          0.985514         12    0.300000  \n",
       "2          0.971200          7    0.250000  \n",
       "3          0.972215          9    0.350000  \n",
       "4          0.989023         14    0.316667  \n",
       "5          0.986642         12    0.383333  \n",
       "6          0.982345         12    0.400000  \n",
       "7          0.979622         10    0.366667  \n",
       "8          0.973791         12    0.383333  \n",
       "9          0.968361          8    0.333333  \n",
       "10         0.972164          8    0.350000  \n",
       "11         0.985015         14    0.416667  \n",
       "12         0.985648         10    0.366667  \n",
       "13         0.982902         11    0.383333  \n",
       "14         0.985405          9    0.283333  \n",
       "15         0.982381         14    0.316667  \n",
       "16         0.966665          9    0.283333  \n",
       "17         0.972929          8    0.266667  \n",
       "18         0.967688          6    0.250000  \n",
       "19         0.982695         10    0.366667  \n",
       "20         0.982224          9    0.350000  \n",
       "21         0.976356          7    0.333333  \n",
       "22         0.980290         11    0.383333  \n",
       "23         0.985141         13    0.400000  \n",
       "24         0.977462          9    0.350000  \n",
       "25         0.970915          8    0.350000  \n",
       "26         0.968540          6    0.316667  \n",
       "27         0.982410         14    0.416667  \n",
       "28         0.987684         14    0.416667  \n",
       "29         0.971993         12    0.383333  \n",
       "30         0.982676         13    0.316667  \n",
       "31         0.972961          8    0.266667  \n",
       "32         0.986605         12    0.300000  \n",
       "33         0.984223         12    0.316667  \n",
       "34         0.987789         13    0.400000  \n",
       "35         0.970854          8    0.333333  \n",
       "36         0.978062         10    0.350000  \n",
       "37         0.978996          8    0.333333  \n",
       "38         0.982701          9    0.350000  \n",
       "39         0.979278          6    0.316667  \n",
       "40         0.983319          6    0.316667  \n",
       "41         0.977669          8    0.333333  \n",
       "42         0.980372          9    0.333333  \n",
       "43         0.987153          8    0.266667  \n",
       "44         0.967668         15    0.400000  \n",
       "45         0.983518         12    0.366667  \n",
       "46         0.970732         13    0.300000  \n",
       "47         0.980120          8    0.266667  \n",
       "48         0.978167         10    0.283333  \n",
       "49         0.975834         13    0.333333  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.979091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.833642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.835442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.978718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>10.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>0.337667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics      value\n",
       "0      train_coverage   0.979091\n",
       "1       test_coverage   0.942500\n",
       "2  avg_ci_width_train   0.833642\n",
       "3   avg_ci_width_test   0.835442\n",
       "4     avg_lstm_weight   0.978718\n",
       "5           exit_iter  10.120000\n",
       "6          time_taken   0.337667"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
