{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = first_lstm[0][3].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                416       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =2\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 16\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "01655210-2a84-49c5-9184-e9bc9064eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    train_lstm = catch1[idx][3].numpy()\n",
    "    valid_lstm = catch1[idx][4].numpy()\n",
    "    # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_doc2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_doc2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_doc2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9545454545454546,\n",
       " 0.875,\n",
       " 0.3475685603131912,\n",
       " 0.3839856529724235,\n",
       " 0.5089305808977053,\n",
       " 116,\n",
       " 0.8333333333333334,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   34.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  2.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  2.8min remaining:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  3.3min remaining:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  3.8min remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  4.1min remaining:   27.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "something went awry\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  5.0min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_966296/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.968460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.903061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.424890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.433669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.538181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>168.510204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>1.139796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics       value\n",
       "0      train_coverage    0.968460\n",
       "1       test_coverage    0.903061\n",
       "2  avg_ci_width_train    0.424890\n",
       "3   avg_ci_width_test    0.433669\n",
       "4     avg_lstm_weight    0.538181\n",
       "5           exit_iter  168.510204\n",
       "6          time_taken    1.139796"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>0.104526</td>\n",
       "      <td>0.515964</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.754559</td>\n",
       "      <td>0.724834</td>\n",
       "      <td>0.534658</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.438231</td>\n",
       "      <td>0.470095</td>\n",
       "      <td>0.565863</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>0.366645</td>\n",
       "      <td>0.517381</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.415013</td>\n",
       "      <td>0.376171</td>\n",
       "      <td>0.514171</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.313171</td>\n",
       "      <td>0.318174</td>\n",
       "      <td>0.730226</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.215273</td>\n",
       "      <td>0.195273</td>\n",
       "      <td>0.524644</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.295173</td>\n",
       "      <td>0.317886</td>\n",
       "      <td>0.522515</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.473850</td>\n",
       "      <td>0.443343</td>\n",
       "      <td>0.507352</td>\n",
       "      <td>318.0</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.361347</td>\n",
       "      <td>0.376489</td>\n",
       "      <td>0.486373</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.283571</td>\n",
       "      <td>0.300062</td>\n",
       "      <td>0.489090</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.428644</td>\n",
       "      <td>0.429840</td>\n",
       "      <td>0.507910</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.544623</td>\n",
       "      <td>0.550228</td>\n",
       "      <td>0.471655</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.549175</td>\n",
       "      <td>0.548885</td>\n",
       "      <td>0.506640</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.195084</td>\n",
       "      <td>0.183419</td>\n",
       "      <td>0.559929</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.401370</td>\n",
       "      <td>0.398673</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.655282</td>\n",
       "      <td>0.678819</td>\n",
       "      <td>0.533511</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996576</td>\n",
       "      <td>0.995659</td>\n",
       "      <td>0.509588</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.506945</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.066633</td>\n",
       "      <td>0.068181</td>\n",
       "      <td>0.576651</td>\n",
       "      <td>223.0</td>\n",
       "      <td>1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.226241</td>\n",
       "      <td>0.231076</td>\n",
       "      <td>0.510462</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552605</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.195066</td>\n",
       "      <td>0.185657</td>\n",
       "      <td>0.511410</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.163418</td>\n",
       "      <td>0.240207</td>\n",
       "      <td>0.469462</td>\n",
       "      <td>436.0</td>\n",
       "      <td>2.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>0.498399</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.539673</td>\n",
       "      <td>0.564820</td>\n",
       "      <td>0.503915</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>0.373597</td>\n",
       "      <td>0.581914</td>\n",
       "      <td>345.0</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.899584</td>\n",
       "      <td>0.930103</td>\n",
       "      <td>0.455238</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422407</td>\n",
       "      <td>0.375368</td>\n",
       "      <td>0.530626</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.222477</td>\n",
       "      <td>0.296544</td>\n",
       "      <td>0.531899</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.316501</td>\n",
       "      <td>0.273597</td>\n",
       "      <td>0.556517</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>0.318513</td>\n",
       "      <td>0.596635</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.134691</td>\n",
       "      <td>0.141446</td>\n",
       "      <td>0.507206</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.259135</td>\n",
       "      <td>0.249671</td>\n",
       "      <td>0.536798</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.477403</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.180266</td>\n",
       "      <td>0.185630</td>\n",
       "      <td>0.511268</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.223899</td>\n",
       "      <td>0.292434</td>\n",
       "      <td>0.671806</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.179675</td>\n",
       "      <td>0.210668</td>\n",
       "      <td>0.637118</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.080310</td>\n",
       "      <td>0.083487</td>\n",
       "      <td>0.535467</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.489454</td>\n",
       "      <td>0.479976</td>\n",
       "      <td>0.511815</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.662187</td>\n",
       "      <td>0.571723</td>\n",
       "      <td>0.536512</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.174808</td>\n",
       "      <td>0.186558</td>\n",
       "      <td>0.537249</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>0.436156</td>\n",
       "      <td>0.774036</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.297819</td>\n",
       "      <td>0.329243</td>\n",
       "      <td>0.546484</td>\n",
       "      <td>269.0</td>\n",
       "      <td>1.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.560391</td>\n",
       "      <td>0.595234</td>\n",
       "      <td>0.528539</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.222417</td>\n",
       "      <td>0.237074</td>\n",
       "      <td>0.494558</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.670923</td>\n",
       "      <td>0.740213</td>\n",
       "      <td>0.571480</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.435728</td>\n",
       "      <td>0.475866</td>\n",
       "      <td>0.559981</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.328190</td>\n",
       "      <td>0.399794</td>\n",
       "      <td>0.557491</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         0.969697          0.875            0.102521           0.104526   \n",
       "1         1.000000          1.000            0.754559           0.724834   \n",
       "2         0.969697          1.000            0.438231           0.470095   \n",
       "3         0.954545          0.875            0.345316           0.366645   \n",
       "4         0.954545          0.875            0.415013           0.376171   \n",
       "5         0.969697          1.000            0.313171           0.318174   \n",
       "6         0.954545          0.750            0.215273           0.195273   \n",
       "7         0.954545          0.875            0.295173           0.317886   \n",
       "8         0.954545          1.000            0.473850           0.443343   \n",
       "9         0.954545          0.875            0.361347           0.376489   \n",
       "10        0.969697          0.875            0.283571           0.300062   \n",
       "11        0.969697          0.875            0.428644           0.429840   \n",
       "12        0.954545          1.000            0.544623           0.550228   \n",
       "13        0.969697          0.875            0.549175           0.548885   \n",
       "14        0.954545          0.750            0.195084           0.183419   \n",
       "15        0.954545          0.875            0.401370           0.398673   \n",
       "16        0.954545          0.750            0.655282           0.678819   \n",
       "17        1.000000          1.000            0.996576           0.995659   \n",
       "18        1.000000          1.000            1.000000           0.999999   \n",
       "19        0.954545          1.000            0.066633           0.068181   \n",
       "20        0.954545          1.000            0.226241           0.231076   \n",
       "21        1.000000          1.000            1.000000           1.000000   \n",
       "22        0.954545          0.875            0.195066           0.185657   \n",
       "23        0.954545          0.625            0.163418           0.240207   \n",
       "24        1.000000          1.000            0.996620           0.997945   \n",
       "25        0.984848          0.875            0.539673           0.564820   \n",
       "26        0.954545          0.500            0.373390           0.373597   \n",
       "27        0.954545          1.000            0.899584           0.930103   \n",
       "28        0.969697          1.000            0.422407           0.375368   \n",
       "29        0.954545          0.625            0.222477           0.296544   \n",
       "30             NaN            NaN                 NaN                NaN   \n",
       "31        0.969697          1.000            0.316501           0.273597   \n",
       "32        0.954545          0.875            0.249137           0.318513   \n",
       "33        0.969697          0.875            0.134691           0.141446   \n",
       "34        0.954545          0.875            0.259135           0.249671   \n",
       "35        1.000000          1.000            1.000000           0.999999   \n",
       "36        0.984848          1.000            0.180266           0.185630   \n",
       "37        0.954545          0.875            0.223899           0.292434   \n",
       "38        0.954545          1.000            0.179675           0.210668   \n",
       "39        0.984848          0.875            0.080310           0.083487   \n",
       "40        0.954545          0.500            0.489454           0.479976   \n",
       "41        1.000000          0.875            0.662187           0.571723   \n",
       "42        0.969697          0.875            0.174808           0.186558   \n",
       "43        0.984848          1.000            0.479806           0.436156   \n",
       "44        0.969697          1.000            0.297819           0.329243   \n",
       "45        0.984848          1.000            0.560391           0.595234   \n",
       "46        0.969697          1.000            0.222417           0.237074   \n",
       "47        0.969697          1.000            0.670923           0.740213   \n",
       "48        0.969697          1.000            0.435728           0.475866   \n",
       "49        0.954545          1.000            0.328190           0.399794   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.515964       54.0    0.416667  \n",
       "1          0.534658      238.0    1.833333  \n",
       "2          0.565863      224.0    1.366667  \n",
       "3          0.517381      117.0    0.883333  \n",
       "4          0.514171      131.0    0.983333  \n",
       "5          0.730226       67.0    0.483333  \n",
       "6          0.524644      109.0    0.833333  \n",
       "7          0.522515      219.0    1.516667  \n",
       "8          0.507352      318.0    1.750000  \n",
       "9          0.486373      221.0    1.566667  \n",
       "10         0.489090      232.0    1.600000  \n",
       "11         0.507910      156.0    1.133333  \n",
       "12         0.471655       60.0    0.516667  \n",
       "13         0.506640      208.0    1.666667  \n",
       "14         0.559929      224.0    1.316667  \n",
       "15         0.495535      132.0    0.750000  \n",
       "16         0.533511       57.0    0.416667  \n",
       "17         0.509588      155.0    1.316667  \n",
       "18         0.506945      161.0    1.350000  \n",
       "19         0.576651      223.0    1.550000  \n",
       "20         0.510462      262.0    1.516667  \n",
       "21         0.552605       20.0    0.450000  \n",
       "22         0.511410      254.0    1.766667  \n",
       "23         0.469462      436.0    2.383333  \n",
       "24         0.498399      232.0    1.483333  \n",
       "25         0.503915      219.0    1.316667  \n",
       "26         0.581914      345.0    2.300000  \n",
       "27         0.455238       65.0    0.550000  \n",
       "28         0.530626      221.0    1.550000  \n",
       "29         0.531899      257.0    1.750000  \n",
       "30              NaN        NaN         NaN  \n",
       "31         0.556517       54.0    0.383333  \n",
       "32         0.596635       76.0    0.616667  \n",
       "33         0.507206       70.0    0.566667  \n",
       "34         0.536798      120.0    0.883333  \n",
       "35         0.477403       41.0    0.500000  \n",
       "36         0.511268      138.0    0.983333  \n",
       "37         0.671806      102.0    0.700000  \n",
       "38         0.637118       49.0    0.433333  \n",
       "39         0.535467      179.0    1.233333  \n",
       "40         0.511815      196.0    1.350000  \n",
       "41         0.536512      295.0    1.616667  \n",
       "42         0.537249      232.0    1.233333  \n",
       "43         0.774036      128.0    0.783333  \n",
       "44         0.546484      269.0    1.683333  \n",
       "45         0.528539      137.0    0.966667  \n",
       "46         0.494558      158.0    1.066667  \n",
       "47         0.571480       53.0    0.466667  \n",
       "48         0.559981       77.0    0.500000  \n",
       "49         0.557491      266.0    1.566667  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
