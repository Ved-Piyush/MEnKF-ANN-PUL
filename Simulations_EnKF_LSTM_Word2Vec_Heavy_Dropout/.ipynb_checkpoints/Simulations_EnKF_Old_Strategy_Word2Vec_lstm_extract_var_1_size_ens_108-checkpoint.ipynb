{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = first_lstm[0][3].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =1\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 16\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01655210-2a84-49c5-9184-e9bc9064eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    train_lstm = catch1[idx][3].numpy()\n",
    "    valid_lstm = catch1[idx][4].numpy()\n",
    "    # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_doc2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_doc2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_doc2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 1.0,\n",
       " 0.43428756307277333,\n",
       " 0.4369336109907499,\n",
       " 0.6056505394868931,\n",
       " 88,\n",
       " 1.0666666666666667,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c9eeee4d-565c-423e-bfa9-b4b4f7135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   28.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   55.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  2.0min remaining:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  2.7min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  3.1min remaining:   52.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  3.3min remaining:   22.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  6.0min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_448891/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7798ea51-ba04-4dcd-9b51-4812a5ea82e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.124678</td>\n",
       "      <td>0.711673</td>\n",
       "      <td>107</td>\n",
       "      <td>1.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.986844</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.485301</td>\n",
       "      <td>51</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.486569</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>92</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.395788</td>\n",
       "      <td>0.548143</td>\n",
       "      <td>211</td>\n",
       "      <td>2.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.380795</td>\n",
       "      <td>0.393464</td>\n",
       "      <td>0.575270</td>\n",
       "      <td>95</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998961</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.541897</td>\n",
       "      <td>14</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992630</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.503996</td>\n",
       "      <td>51</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997036</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>0.487887</td>\n",
       "      <td>99</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.516641</td>\n",
       "      <td>30</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.482437</td>\n",
       "      <td>28</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>0.525570</td>\n",
       "      <td>10</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995196</td>\n",
       "      <td>0.997496</td>\n",
       "      <td>0.516217</td>\n",
       "      <td>51</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.499747</td>\n",
       "      <td>12</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999157</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.519341</td>\n",
       "      <td>38</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.992819</td>\n",
       "      <td>0.473010</td>\n",
       "      <td>56</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.960128</td>\n",
       "      <td>0.927428</td>\n",
       "      <td>0.520884</td>\n",
       "      <td>172</td>\n",
       "      <td>2.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.519095</td>\n",
       "      <td>41</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.499308</td>\n",
       "      <td>14</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.463471</td>\n",
       "      <td>107</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998336</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.488205</td>\n",
       "      <td>56</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.504404</td>\n",
       "      <td>34</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.508102</td>\n",
       "      <td>82</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995873</td>\n",
       "      <td>0.991154</td>\n",
       "      <td>0.502554</td>\n",
       "      <td>52</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.507859</td>\n",
       "      <td>69</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.468963</td>\n",
       "      <td>75</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.527330</td>\n",
       "      <td>29</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.613029</td>\n",
       "      <td>0.636280</td>\n",
       "      <td>0.564754</td>\n",
       "      <td>154</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>0.998916</td>\n",
       "      <td>0.507915</td>\n",
       "      <td>63</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999195</td>\n",
       "      <td>0.996677</td>\n",
       "      <td>0.532481</td>\n",
       "      <td>52</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992907</td>\n",
       "      <td>0.988633</td>\n",
       "      <td>0.519760</td>\n",
       "      <td>34</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.251933</td>\n",
       "      <td>0.197870</td>\n",
       "      <td>0.579039</td>\n",
       "      <td>194</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.420040</td>\n",
       "      <td>0.443915</td>\n",
       "      <td>0.654629</td>\n",
       "      <td>80</td>\n",
       "      <td>1.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.131572</td>\n",
       "      <td>0.149196</td>\n",
       "      <td>0.543063</td>\n",
       "      <td>117</td>\n",
       "      <td>1.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.497027</td>\n",
       "      <td>10</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.504712</td>\n",
       "      <td>109</td>\n",
       "      <td>1.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.524319</td>\n",
       "      <td>89</td>\n",
       "      <td>1.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.257561</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.510379</td>\n",
       "      <td>202</td>\n",
       "      <td>2.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.162038</td>\n",
       "      <td>0.187530</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>95</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.498615</td>\n",
       "      <td>47</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.518329</td>\n",
       "      <td>98</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.998457</td>\n",
       "      <td>0.460282</td>\n",
       "      <td>94</td>\n",
       "      <td>1.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.998363</td>\n",
       "      <td>0.536693</td>\n",
       "      <td>33</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.880884</td>\n",
       "      <td>0.918984</td>\n",
       "      <td>0.593695</td>\n",
       "      <td>106</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.488155</td>\n",
       "      <td>31</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.420841</td>\n",
       "      <td>0.427417</td>\n",
       "      <td>0.566586</td>\n",
       "      <td>359</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.999187</td>\n",
       "      <td>0.487233</td>\n",
       "      <td>40</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.845015</td>\n",
       "      <td>0.833567</td>\n",
       "      <td>0.579724</td>\n",
       "      <td>102</td>\n",
       "      <td>1.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.427154</td>\n",
       "      <td>0.460667</td>\n",
       "      <td>0.605730</td>\n",
       "      <td>85</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.495486</td>\n",
       "      <td>33</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         0.954545          0.875            0.108446           0.124678   \n",
       "1         1.000000          1.000            0.986844           0.984127   \n",
       "2         1.000000          1.000            0.999995           0.999998   \n",
       "3         1.000000          1.000            0.999256           0.999488   \n",
       "4         0.954545          1.000            0.429000           0.395788   \n",
       "5         0.954545          1.000            0.380795           0.393464   \n",
       "6         1.000000          1.000            0.998961           0.999383   \n",
       "7         1.000000          1.000            0.992630           0.995316   \n",
       "8         1.000000          1.000            0.997036           0.996120   \n",
       "9         1.000000          1.000            0.999996           0.999996   \n",
       "10        1.000000          1.000            0.999965           0.999970   \n",
       "11        1.000000          1.000            0.996455           0.996857   \n",
       "12        1.000000          1.000            0.995196           0.997496   \n",
       "13        1.000000          1.000            0.998696           0.999158   \n",
       "14        1.000000          1.000            0.999157           0.999854   \n",
       "15        1.000000          1.000            0.991111           0.992819   \n",
       "16        0.954545          0.875            0.960128           0.927428   \n",
       "17        1.000000          1.000            0.999997           0.999993   \n",
       "18        1.000000          1.000            0.999999           0.999998   \n",
       "19        1.000000          1.000            0.998382           0.998941   \n",
       "20        1.000000          1.000            0.998336           0.998924   \n",
       "21        1.000000          1.000            0.999999           0.999998   \n",
       "22        1.000000          1.000            0.999802           0.999859   \n",
       "23        1.000000          1.000            0.995873           0.991154   \n",
       "24        1.000000          1.000            0.999436           0.999944   \n",
       "25        1.000000          1.000            0.999973           0.999969   \n",
       "26        1.000000          1.000            0.999996           0.999996   \n",
       "27        0.984848          1.000            0.613029           0.636280   \n",
       "28        1.000000          1.000            0.998084           0.998916   \n",
       "29        1.000000          1.000            0.999195           0.996677   \n",
       "30        1.000000          1.000            0.992907           0.988633   \n",
       "31        0.969697          1.000            0.251933           0.197870   \n",
       "32        0.954545          0.875            0.420040           0.443915   \n",
       "33        0.969697          0.875            0.131572           0.149196   \n",
       "34        1.000000          1.000            0.999464           0.999813   \n",
       "35        1.000000          1.000            0.999998           0.999994   \n",
       "36        1.000000          1.000            0.999982           0.999971   \n",
       "37        0.969697          0.875            0.257561           0.284483   \n",
       "38        0.954545          0.875            0.162038           0.187530   \n",
       "39        1.000000          1.000            0.999917           0.999859   \n",
       "40        1.000000          1.000            0.999734           0.999601   \n",
       "41        1.000000          1.000            0.998776           0.998457   \n",
       "42        1.000000          1.000            0.999670           0.998363   \n",
       "43        1.000000          1.000            0.880884           0.918984   \n",
       "44        1.000000          1.000            0.999444           0.999047   \n",
       "45        0.954545          1.000            0.420841           0.427417   \n",
       "46        1.000000          1.000            0.998826           0.999187   \n",
       "47        0.954545          1.000            0.845015           0.833567   \n",
       "48        0.954545          1.000            0.427154           0.460667   \n",
       "49        1.000000          1.000            0.999516           0.999510   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.711673        107    1.433333  \n",
       "1          0.485301         51    0.783333  \n",
       "2          0.486569         11    0.366667  \n",
       "3          0.516957         92    1.100000  \n",
       "4          0.548143        211    2.550000  \n",
       "5          0.575270         95    1.083333  \n",
       "6          0.541897         14    0.400000  \n",
       "7          0.503996         51    0.800000  \n",
       "8          0.487887         99    1.333333  \n",
       "9          0.516641         30    0.566667  \n",
       "10         0.482437         28    0.433333  \n",
       "11         0.525570         10    0.350000  \n",
       "12         0.516217         51    0.650000  \n",
       "13         0.499747         12    0.366667  \n",
       "14         0.519341         38    0.650000  \n",
       "15         0.473010         56    0.750000  \n",
       "16         0.520884        172    2.150000  \n",
       "17         0.519095         41    0.683333  \n",
       "18         0.499308         14    0.383333  \n",
       "19         0.463471        107    1.200000  \n",
       "20         0.488205         56    0.850000  \n",
       "21         0.504404         34    0.600000  \n",
       "22         0.508102         82    0.883333  \n",
       "23         0.502554         52    0.800000  \n",
       "24         0.507859         69    0.983333  \n",
       "25         0.468963         75    1.050000  \n",
       "26         0.527330         29    0.533333  \n",
       "27         0.564754        154    1.600000  \n",
       "28         0.507915         63    0.816667  \n",
       "29         0.532481         52    0.616667  \n",
       "30         0.519760         34    0.600000  \n",
       "31         0.579039        194    2.300000  \n",
       "32         0.654629         80    1.116667  \n",
       "33         0.543063        117    1.483333  \n",
       "34         0.497027         10    0.266667  \n",
       "35         0.504712        109    1.416667  \n",
       "36         0.524319         89    1.016667  \n",
       "37         0.510379        202    2.283333  \n",
       "38         0.574648         95    1.066667  \n",
       "39         0.498615         47    0.733333  \n",
       "40         0.518329         98    1.083333  \n",
       "41         0.460282         94    1.216667  \n",
       "42         0.536693         33    0.583333  \n",
       "43         0.593695        106    1.166667  \n",
       "44         0.488155         31    0.550000  \n",
       "45         0.566586        359    3.333333  \n",
       "46         0.487233         40    0.633333  \n",
       "47         0.579724        102    1.216667  \n",
       "48         0.605730         85    1.083333  \n",
       "49         0.495486         33    0.433333  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.989697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.844421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.846173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.524882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>78.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>1.007000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics      value\n",
       "0      train_coverage   0.989697\n",
       "1       test_coverage   0.985000\n",
       "2  avg_ci_width_train   0.844421\n",
       "3   avg_ci_width_test   0.846173\n",
       "4     avg_lstm_weight   0.524882\n",
       "5           exit_iter  78.280000\n",
       "6          time_taken   1.007000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
