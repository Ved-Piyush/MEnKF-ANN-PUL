{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//Heavy_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Heavy_Dropout//heavy_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = first_lstm[0][3].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                416       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =1\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 16\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "01655210-2a84-49c5-9184-e9bc9064eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    train_lstm = catch1[idx][3].numpy()\n",
    "    valid_lstm = catch1[idx][4].numpy()\n",
    "    # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_doc2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_doc2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_doc2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "        # print(\"epoch \"+ str(iter1))\n",
    "        # print(\"patience smaller \"+ str(patience_smaller))\n",
    "        # print(\"patience uns \"+ str(patience_uns))\n",
    "        # # print(\"test mae is \" + str(test_mae))\n",
    "        # print(\"train coverage is \"+ str(coverage_train))\n",
    "        # print(\"train width is \" + str(avg_width_train))        \n",
    "        # print(\"test coverage is \"+ str(coverage_test))\n",
    "        # print(\"test width is \" + str(avg_width))\n",
    "        # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9696969696969697,\n",
       " 1.0,\n",
       " 0.42777372794291946,\n",
       " 0.45267593751106605,\n",
       " 0.6748390526611102,\n",
       " 32,\n",
       " 0.2833333333333333,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c9eeee4d-565c-423e-bfa9-b4b4f7135d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   32.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  2.3min remaining:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  2.7min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  3.2min remaining:   53.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  3.6min remaining:   23.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_448891/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7798ea51-ba04-4dcd-9b51-4812a5ea82e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>0.213130</td>\n",
       "      <td>0.646810</td>\n",
       "      <td>63</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.470555</td>\n",
       "      <td>0.459413</td>\n",
       "      <td>0.515679</td>\n",
       "      <td>287</td>\n",
       "      <td>1.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.531754</td>\n",
       "      <td>16</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.391014</td>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.521828</td>\n",
       "      <td>49</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.522093</td>\n",
       "      <td>0.541559</td>\n",
       "      <td>0.556583</td>\n",
       "      <td>106</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.401431</td>\n",
       "      <td>0.410924</td>\n",
       "      <td>0.635933</td>\n",
       "      <td>40</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.215525</td>\n",
       "      <td>0.228051</td>\n",
       "      <td>0.552963</td>\n",
       "      <td>97</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.315040</td>\n",
       "      <td>0.318884</td>\n",
       "      <td>0.519215</td>\n",
       "      <td>173</td>\n",
       "      <td>1.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.872051</td>\n",
       "      <td>0.875144</td>\n",
       "      <td>0.518994</td>\n",
       "      <td>288</td>\n",
       "      <td>2.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.991121</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.504834</td>\n",
       "      <td>161</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.398429</td>\n",
       "      <td>0.529244</td>\n",
       "      <td>0.517487</td>\n",
       "      <td>191</td>\n",
       "      <td>1.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.893451</td>\n",
       "      <td>0.907509</td>\n",
       "      <td>0.528323</td>\n",
       "      <td>59</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.729738</td>\n",
       "      <td>0.722913</td>\n",
       "      <td>0.586786</td>\n",
       "      <td>54</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.173120</td>\n",
       "      <td>0.172390</td>\n",
       "      <td>0.537576</td>\n",
       "      <td>187</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.181548</td>\n",
       "      <td>0.189548</td>\n",
       "      <td>0.548747</td>\n",
       "      <td>160</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.362083</td>\n",
       "      <td>0.339629</td>\n",
       "      <td>0.517577</td>\n",
       "      <td>238</td>\n",
       "      <td>1.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.799534</td>\n",
       "      <td>0.816894</td>\n",
       "      <td>0.594443</td>\n",
       "      <td>76</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.511160</td>\n",
       "      <td>93</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.524656</td>\n",
       "      <td>43</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.106927</td>\n",
       "      <td>0.086606</td>\n",
       "      <td>0.545698</td>\n",
       "      <td>208</td>\n",
       "      <td>1.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.409633</td>\n",
       "      <td>0.523960</td>\n",
       "      <td>167</td>\n",
       "      <td>1.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.345654</td>\n",
       "      <td>0.342806</td>\n",
       "      <td>0.466166</td>\n",
       "      <td>321</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.202904</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.547834</td>\n",
       "      <td>172</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>0.219155</td>\n",
       "      <td>0.472156</td>\n",
       "      <td>208</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.280066</td>\n",
       "      <td>0.273459</td>\n",
       "      <td>0.527253</td>\n",
       "      <td>305</td>\n",
       "      <td>2.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.997711</td>\n",
       "      <td>0.509654</td>\n",
       "      <td>161</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.474399</td>\n",
       "      <td>6</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.778079</td>\n",
       "      <td>0.797976</td>\n",
       "      <td>0.502230</td>\n",
       "      <td>46</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.390135</td>\n",
       "      <td>0.382986</td>\n",
       "      <td>0.547645</td>\n",
       "      <td>153</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.235337</td>\n",
       "      <td>0.262439</td>\n",
       "      <td>0.524349</td>\n",
       "      <td>164</td>\n",
       "      <td>1.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.804468</td>\n",
       "      <td>0.522225</td>\n",
       "      <td>160</td>\n",
       "      <td>1.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.231673</td>\n",
       "      <td>0.205105</td>\n",
       "      <td>0.576885</td>\n",
       "      <td>95</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.258290</td>\n",
       "      <td>0.330733</td>\n",
       "      <td>0.630580</td>\n",
       "      <td>45</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.134169</td>\n",
       "      <td>0.142463</td>\n",
       "      <td>0.533850</td>\n",
       "      <td>48</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.280327</td>\n",
       "      <td>0.275342</td>\n",
       "      <td>0.536898</td>\n",
       "      <td>76</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.507061</td>\n",
       "      <td>174</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.206595</td>\n",
       "      <td>0.224955</td>\n",
       "      <td>0.564426</td>\n",
       "      <td>242</td>\n",
       "      <td>1.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.442938</td>\n",
       "      <td>0.479036</td>\n",
       "      <td>0.499547</td>\n",
       "      <td>133</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.238798</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>0.587867</td>\n",
       "      <td>62</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.057467</td>\n",
       "      <td>0.518128</td>\n",
       "      <td>295</td>\n",
       "      <td>1.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.991996</td>\n",
       "      <td>0.991614</td>\n",
       "      <td>0.537609</td>\n",
       "      <td>151</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.418841</td>\n",
       "      <td>0.278025</td>\n",
       "      <td>0.519586</td>\n",
       "      <td>257</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.235149</td>\n",
       "      <td>0.268481</td>\n",
       "      <td>0.551531</td>\n",
       "      <td>264</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.329930</td>\n",
       "      <td>0.287416</td>\n",
       "      <td>0.531813</td>\n",
       "      <td>126</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.387504</td>\n",
       "      <td>0.448243</td>\n",
       "      <td>0.504539</td>\n",
       "      <td>136</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.481870</td>\n",
       "      <td>0.510416</td>\n",
       "      <td>0.517614</td>\n",
       "      <td>75</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.205412</td>\n",
       "      <td>0.244497</td>\n",
       "      <td>0.555750</td>\n",
       "      <td>148</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.863084</td>\n",
       "      <td>0.855678</td>\n",
       "      <td>0.583010</td>\n",
       "      <td>49</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.373849</td>\n",
       "      <td>0.369905</td>\n",
       "      <td>0.636569</td>\n",
       "      <td>33</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.299859</td>\n",
       "      <td>0.319968</td>\n",
       "      <td>0.544473</td>\n",
       "      <td>211</td>\n",
       "      <td>1.316667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         0.954545          0.875            0.180743           0.213130   \n",
       "1         1.000000          1.000            0.470555           0.459413   \n",
       "2         1.000000          1.000            0.999803           0.999942   \n",
       "3         0.954545          1.000            0.391014           0.449902   \n",
       "4         0.954545          1.000            0.522093           0.541559   \n",
       "5         0.969697          1.000            0.401431           0.410924   \n",
       "6         0.954545          0.750            0.215525           0.228051   \n",
       "7         0.954545          0.875            0.315040           0.318884   \n",
       "8         1.000000          1.000            0.872051           0.875144   \n",
       "9         1.000000          1.000            0.991121           0.990458   \n",
       "10        0.969697          0.875            0.398429           0.529244   \n",
       "11        0.984848          1.000            0.893451           0.907509   \n",
       "12        0.969697          1.000            0.729738           0.722913   \n",
       "13        0.954545          0.875            0.173120           0.172390   \n",
       "14        0.954545          0.750            0.181548           0.189548   \n",
       "15        0.954545          0.875            0.362083           0.339629   \n",
       "16        0.954545          0.875            0.799534           0.816894   \n",
       "17        1.000000          1.000            0.999992           0.999985   \n",
       "18        1.000000          1.000            0.999955           0.999901   \n",
       "19        0.984848          1.000            0.106927           0.086606   \n",
       "20        0.969697          1.000            0.404878           0.409633   \n",
       "21        0.969697          0.875            0.345654           0.342806   \n",
       "22        0.969697          0.875            0.202904           0.181972   \n",
       "23        0.954545          0.625            0.154518           0.219155   \n",
       "24        0.984848          0.875            0.280066           0.273459   \n",
       "25        1.000000          1.000            0.997776           0.997711   \n",
       "26        1.000000          1.000            0.999939           0.999923   \n",
       "27        0.954545          1.000            0.778079           0.797976   \n",
       "28        0.969697          1.000            0.390135           0.382986   \n",
       "29        0.954545          0.500            0.235337           0.262439   \n",
       "30        0.984848          0.875            0.812482           0.804468   \n",
       "31        0.969697          1.000            0.231673           0.205105   \n",
       "32        0.954545          0.875            0.258290           0.330733   \n",
       "33        0.969697          0.875            0.134169           0.142463   \n",
       "34        0.969697          0.875            0.280327           0.275342   \n",
       "35        1.000000          1.000            0.999315           0.998865   \n",
       "36        0.984848          1.000            0.206595           0.224955   \n",
       "37        0.954545          0.875            0.442938           0.479036   \n",
       "38        0.984848          1.000            0.238798           0.251709   \n",
       "39        0.984848          0.875            0.056711           0.057467   \n",
       "40        0.954545          1.000            0.991996           0.991614   \n",
       "41        0.969697          0.875            0.418841           0.278025   \n",
       "42        0.969697          0.875            0.235149           0.268481   \n",
       "43        0.954545          0.875            0.329930           0.287416   \n",
       "44        0.954545          1.000            0.387504           0.448243   \n",
       "45        0.969697          1.000            0.481870           0.510416   \n",
       "46        0.954545          1.000            0.205412           0.244497   \n",
       "47        0.954545          1.000            0.863084           0.855678   \n",
       "48        0.954545          0.875            0.373849           0.369905   \n",
       "49        0.954545          1.000            0.299859           0.319968   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.646810         63    0.483333  \n",
       "1          0.515679        287    1.533333  \n",
       "2          0.531754         16    0.433333  \n",
       "3          0.521828         49    0.450000  \n",
       "4          0.556583        106    0.700000  \n",
       "5          0.635933         40    0.350000  \n",
       "6          0.552963         97    0.683333  \n",
       "7          0.519215        173    1.233333  \n",
       "8          0.518994        288    2.183333  \n",
       "9          0.504834        161    1.350000  \n",
       "10         0.517487        191    1.366667  \n",
       "11         0.528323         59    0.516667  \n",
       "12         0.586786         54    0.483333  \n",
       "13         0.537576        187    1.333333  \n",
       "14         0.548747        160    1.150000  \n",
       "15         0.517577        238    1.366667  \n",
       "16         0.594443         76    0.616667  \n",
       "17         0.511160         93    0.900000  \n",
       "18         0.524656         43    0.450000  \n",
       "19         0.545698        208    1.466667  \n",
       "20         0.523960        167    1.216667  \n",
       "21         0.466166        321    1.833333  \n",
       "22         0.547834        172    1.083333  \n",
       "23         0.472156        208    1.200000  \n",
       "24         0.527253        305    2.116667  \n",
       "25         0.509654        161    1.350000  \n",
       "26         0.474399          6    0.366667  \n",
       "27         0.502230         46    0.433333  \n",
       "28         0.547645        153    1.100000  \n",
       "29         0.524349        164    1.183333  \n",
       "30         0.522225        160    1.316667  \n",
       "31         0.576885         95    0.650000  \n",
       "32         0.630580         45    0.416667  \n",
       "33         0.533850         48    0.333333  \n",
       "34         0.536898         76    0.616667  \n",
       "35         0.507061        174    1.400000  \n",
       "36         0.564426        242    1.366667  \n",
       "37         0.499547        133    0.966667  \n",
       "38         0.587867         62    0.483333  \n",
       "39         0.518128        295    1.850000  \n",
       "40         0.537609        151    1.083333  \n",
       "41         0.519586        257    1.400000  \n",
       "42         0.551531        264    1.450000  \n",
       "43         0.531813        126    0.900000  \n",
       "44         0.504539        136    0.950000  \n",
       "45         0.517614         75    0.483333  \n",
       "46         0.555750        148    0.983333  \n",
       "47         0.583010         49    0.450000  \n",
       "48         0.636569         33    0.250000  \n",
       "49         0.544473        211    1.316667  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.970909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.480845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.489289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.539453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>141.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics       value\n",
       "0      train_coverage    0.970909\n",
       "1       test_coverage    0.925000\n",
       "2  avg_ci_width_train    0.480845\n",
       "3   avg_ci_width_test    0.489289\n",
       "4     avg_lstm_weight    0.539453\n",
       "5           exit_iter  141.440000\n",
       "6          time_taken    0.992000"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
