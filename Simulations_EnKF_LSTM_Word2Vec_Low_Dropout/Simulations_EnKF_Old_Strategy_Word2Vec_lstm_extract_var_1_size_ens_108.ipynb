{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.word2vec.Word2Vec.load(r\"..//Data_Generation//word2vec_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fbb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88bbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440c1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//Data//train_valid_test_splits_50.pkl', 'rb') as f:\n",
    "    catch = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb870fe-f1ca-4a5b-9090-ab79a7752959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Low_Dropout//low_dropout_first_lstm.pkl', 'rb') as f:\n",
    "    first_lstm = pickle.load(f)  \n",
    "\n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_train_logits.pkl', 'rb') as f:\n",
    "    catch_train_logits = (pickle.load(f))    \n",
    "\n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_valid_logits.pkl', 'rb') as f:\n",
    "    catch_valid_logits = (pickle.load( f))      \n",
    "    \n",
    "with open('..//Data_Generation//LSTM_Low_Dropout//Low_Data_test_logits.pkl', 'rb') as f:\n",
    "    catch_test_logits = (pickle.load( f))      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cebd632-4619-43f8-9d84-5782ad877764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//Data_Generation//LSTM_Low_Dropout//low_dropout_second_lstm.pkl', 'rb') as f:\n",
    "    second_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fdce782-35ce-4f39-923d-4314c6901f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = first_lstm[0][3].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 25)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = model_cbow.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =1\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 16\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb2ae5fe-5ecd-4b45-a492-883966cf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch1 = second_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c85e883d-83e4-4d04-b57b-0d51dc7a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37652648-24b1-45af-917f-a16df5ac647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(catch1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01655210-2a84-49c5-9184-e9bc9064eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"..//Data_Generation//doc2vec_dbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee1409a5-7760-41cc-95d8-1465e8996744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch_train_logits[0] , catch_valid_logits[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96b96036-d65c-47f6-80e8-e7a27164ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expit(np.vstack((catch1[0][0], catch1[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9041a146-355b-45ff-abc5-7dfae73ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c553b08-1d5b-474c-8837-6b55dc6cc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100\n",
    "    \n",
    "    X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "    log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    train_lstm = catch1[idx][3].numpy()\n",
    "    valid_lstm = catch1[idx][4].numpy()\n",
    "    # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "    # train_doc2vec = []\n",
    "    X_train_doc_vectors = []\n",
    "    vocab = model.wv.index_to_key\n",
    "    vec_size = model.wv.vectors.shape[1]\n",
    "    \n",
    "    for train_item in catch[idx][0]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_train_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_train_doc_vectors.append(np.array(word_vectors).mean(0).tolist())\n",
    "            \n",
    "    train_doc2vec = np.array(X_train_doc_vectors)        \n",
    "            \n",
    "    X_valid_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][1]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_valid_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_valid_doc_vectors.append(np.array(word_vectors).mean(0).tolist())    \n",
    "            \n",
    "    valid_doc2vec = np.array(X_valid_doc_vectors)         \n",
    "            \n",
    "    X_test_doc_vectors = []\n",
    "    # vocab = model.wv.index_to_key\n",
    "    for train_item in  catch[idx][2]:\n",
    "        train_item = train_item[0].replace(\"|\", \",\").split(\",\")\n",
    "        word_vectors = []\n",
    "        for word in train_item: \n",
    "            if word in vocab:\n",
    "                word_vectors.append(model.wv.get_vector(word).reshape(1,-1).tolist()[0])\n",
    "            else:\n",
    "                word_vectors.append(np.zeros((1,vec_size)).reshape(1,-1).tolist()[0])\n",
    "                \n",
    "                \n",
    "        if len(word_vectors) == 0: \n",
    "            X_test_doc_vectors.append(np.zeros((1,vec_size)).tolist()[0])\n",
    "        else:\n",
    "            X_test_doc_vectors.append(np.array(word_vectors).mean(0).tolist())   \n",
    "\n",
    "    test_doc2vec = np.array(X_test_doc_vectors)\n",
    "            \n",
    "    train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "    train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))\n",
    "    \n",
    "\n",
    "    threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start=datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "\n",
    "        for batch_idx in batch_chunks:\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            \n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            ind_test = (expit(catch_test_logits[idx]) >= li) & (expit(catch_test_logits[idx]) <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "            \n",
    "            # test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets.ravel()))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "    \n",
    "        # print(\"best train width is\" + str(best_train_width))\n",
    "              \n",
    "    \n",
    "        if (coverage_train > best_coverage_train) & (coverage_train < 0.95) & (threshold_achieved == False): \n",
    "            cur_best_train_width = avg_width_train\n",
    "            cur_best_test_width = avg_width\n",
    "\n",
    "            cur_best_train_coverage = coverage_train\n",
    "            cur_best_test_coverage = coverage_test \n",
    "            cur_best_lstm_weight = np.mean(complement)\n",
    "            best_coverage_train = coverage_train\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            patience_uns = 0\n",
    "            threshold_achieved = False\n",
    "            # satisfactory = True\n",
    "            \n",
    "        elif (coverage_train < best_coverage_train) & (coverage_train < 0.95)& (threshold_achieved == False): \n",
    "            patience_uns += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with less than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train >= 0.95):\n",
    "            # print(\"going here\")\n",
    "            # print(\"entered\")\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            \n",
    "            best_lstm_weight = np.mean(complement)\n",
    "\n",
    "            patience_smaller = 0 \n",
    "            \n",
    "            threshold_achieved = True\n",
    "            exit_iter_thresh = iter1\n",
    "            best_test_preds = initial_targets_softmax\n",
    "            \n",
    "        elif (avg_width_train > best_train_width) & (coverage_train >= 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        elif (threshold_achieved == True) & (coverage_train < 0.95):\n",
    "            patience_smaller +=1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            # print(\"something wrong with greater than 0.95 case\", flush = True)\n",
    "            \n",
    "            \n",
    "#         print(\"epoch \"+ str(iter1))\n",
    "#         print(\"patience smaller \"+ str(patience_smaller))\n",
    "#         print(\"patience uns \"+ str(patience_uns))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "#         print(\"train coverage is \"+ str(coverage_train))\n",
    "#         print(\"train width is \" + str(avg_width_train))        \n",
    "#         print(\"test coverage is \"+ str(coverage_test))\n",
    "#         print(\"test width is \" + str(avg_width))\n",
    "#         print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         print(\"threshold \" + str(threshold_achieved))\n",
    "            \n",
    "            \n",
    "        if (threshold_achieved == True) & (coverage_train < 0.95) & (patience_smaller > threshold):\n",
    "            # patience_smaller += 1 \n",
    "            # if patience_smaller > threshold:\n",
    "            print(\"thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0\n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"thresh_achieved\", mins ,best_test_preds\n",
    "        \n",
    "        elif (patience_uns > uns_iter_threshold) & (threshold_achieved == False):\n",
    "            print(\"cutting off thresh not achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0            \n",
    "            return cur_best_train_coverage, cur_best_test_coverage, cur_best_train_width, cur_best_test_width, cur_best_lstm_weight, exit_iter_no_thresh,  \"cutoff_thresh_not_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (patience_smaller > cutoff_threshold) & (threshold_achieved == True) & (coverage_train > 0.95):\n",
    "            print(\"cutting off thresh achieved\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved\",mins, best_test_preds\n",
    "        \n",
    "        elif (best_train_width == 1.0)  & (iter1 > break_threshold):\n",
    "                \n",
    "            print(\"cutting off due to stagnation\", flush = True)\n",
    "            stop = datetime.now()\n",
    "            tt = stop-start\n",
    "            mins = tt.seconds/60.0              \n",
    "            return best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, \"cutoff_thresh_achieved_stagnation\",mins, best_test_preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f0f0d3-7aaa-42ce-83c8-4dd5dacedaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_iter_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae354b0-781d-41da-9426-2a8f46695287",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3722374-17be-4906-87b5-5af646f03cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eceba9b-92f4-41cf-ac6d-f860917b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cbca15-cb9b-48be-ba91-7a1b7b164526",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "855b04fa-e71c-4c4f-b81d-38b03eeb4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh, status, time_taken, best_test_preds = rep_one(cur_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84e0d8ba-e52a-4ae7-ad4d-e440d1008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9696969696969697,\n",
       " 1.0,\n",
       " 0.5179106602741197,\n",
       " 0.5095683063478738,\n",
       " 0.48807376244794304,\n",
       " 107,\n",
       " 0.7166666666666667,\n",
       " 'thresh_achieved')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_coverage, best_test_coverage, best_train_width, best_test_width, best_lstm_weight, exit_iter_thresh,time_taken, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7508d4a1-27b7-4d22-8152-43f1e91872b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([426.,  23.,   8.,   8.,  14.,  11.,   8.,  13.,  37., 316.]),\n",
       " array([5.24754979e-05, 1.00045730e-01, 2.00038985e-01, 3.00032240e-01,\n",
       "        4.00025494e-01, 5.00018749e-01, 6.00012004e-01, 7.00005259e-01,\n",
       "        7.99998513e-01, 8.99991768e-01, 9.99985023e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(best_test_preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c0877a1-62fd-4251-a37d-20163e40b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,8): \n",
    "#     axs[i].hist(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])))\n",
    "#     ci = np.percentile(np.log(best_test_preds[:,i,:]/(1-best_test_preds[:,i,:])), q = (2.5, 97.5))\n",
    "#     l, u = ci[0], ci[1]\n",
    "#     axs[i].axvline(x=np.log(expit(catch_test_logits[cur_idx][i])/(1-expit(catch_test_logits[cur_idx][i]))), color = \"red\")\n",
    "#     axs[i].axvline(x=l, color = \"green\")\n",
    "#     axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c348526e-3243-4c83-bbd5-10d68ac1cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAAH9CAYAAAAdwf8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQhUlEQVR4nO3df3DUdZ7n8VcboEm4JDrM0J2cAcJeACE6ImGBwJnsauI6QM0cd7oadFB3p8IFRyJ3E8kyOg0r3cBqNjeyhoOyIJYVsHaVGaocMakZCeNE14BhxgkszI0IOSSXcjaVRH50FvjcH2x6aBLIt0N3f/vH81H1qUp/vp/ufL7f/r772+/+fL+fr8MYYwQAAAAAAIZ1i90dAAAAAAAgXpBEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaRRAMAAAAAYBFJNAAAAAAAFpFEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGBRSEn0xYsX9cMf/lC5ublKTU3VlClTtH79el2+fDnQxhgjj8ej7Oxspaamqri4WO3t7WHvOAAAyYxjMgAA9hgVSuNNmzZp69atqq+v18yZM3Xw4EE9+eSTyszM1KpVqyRJmzdvVk1NjXbu3KmpU6fqxRdfVElJiY4dO6b09PRh/8fly5f1xRdfKD09XQ6HY2RrBSQBY4z6+vqUnZ2tW26JvZNKiGVgeDcTx9E4JkvEMmAFx2Qg/oUUxyYEixYtMk899VRQ3dKlS81jjz1mjDHm8uXLxu12m40bNwaWX7hwwWRmZpqtW7da+h8dHR1GEoVCsVg6OjpCCeOoIZYpFOtlJHEcjWMysUyhhFY4JlMo8V+sxHFII9ELFy7U1q1bdfz4cU2dOlW//vWv9cEHH6i2tlaSdOLECXV2dqq0tDTwHKfTqaKiIrW0tKi8vHzQa/r9fvn9/sBjY4wkqaOjQxkZGaF0L2Rn+88q++VsSdIX/+MLjRszLqL/Dwnu7Fkp+8r+pC++kMaFvj+Fsk/29vYqJyfH8mhStA30KxqxPICYRsRZjHOr++LNxHEkjsnSyI7LxJ7CcgxIRomy7yTCMTlR3ouQELcxIxb2v1DiOKQk+rnnnlNPT4+mT5+ulJQUXbp0SRs2bNCjjz4qSers7JQkuVyuoOe5XC6dPHlyyNf0+Xxat27doPqMjIyIf/FO6U+Rxv7x/yXFhwUiJyXlj39nZIzog3gk+2SsnpY10K9oxPIAYhoRZzHOQ90XRxLHkTgmSyM7LhN7CssxIBkl2r4Tz8fkRHsvLCFuY0Ys7X9W4jikizbefPNNvfHGG2poaNAnn3yi+vp6vfTSS6qvr7/hPzbGXLcz1dXV6unpCZSOjo5QugQAQFKKxDFZ4rgMAMBwQhqJ/sEPfqA1a9bokUcekSTdeeedOnnypHw+n5YvXy632y3pyq/fWVlZged1dXUN+iV8gNPplNPpHGn/AQBISpE4JksclwEAGE5II9Hnzp0bNFNZSkpK4HYaubm5crvdampqCizv7+9Xc3OzCgsLw9BdAAAgcUwGAMAuIY1EL1myRBs2bNDEiRM1c+ZMtbW1qaamRk899ZSkK6eMVVZWyuv1Ki8vT3l5efJ6vUpLS1NZWVlEVgAAgGTEMRkAAHuElES/8sorev7551VRUaGuri5lZ2ervLxcL7zwQqBNVVWVzp8/r4qKCnV3d2vu3LlqbGyM2dkKAQCIRxyTAQCwR0hJdHp6umprawO3zxiKw+GQx+ORx+O5ya4BAIDr4ZgMAIA9QromGgAAAACAZBbSSDQAa+54fp/Ojxkb8vMu64KUGoEOAQjJ5DXvDFmf2n9BR//97xvFeTLH8h0v7NMtCv3zb8DnGxeFsTcARuJm41gilpHYGIkGktDFixf1wx/+ULm5uUpNTdWUKVO0fv36wKy+0pV7yXo8HmVnZys1NVXFxcVqb2+3sdcAAACA/UiigSS0adMmbd26VVu2bNHRo0e1efNm/d3f/Z1eeeWVQJvNmzerpqZGW7ZsUWtrq9xut0pKStTX12djzwEAAAB7kUQDSejDDz/Ut7/9bS1atEiTJ0/Wf/tv/02lpaU6ePCgpCuj0LW1tVq7dq2WLl2q/Px81dfX69y5c2poaLC59wAAAIB9SKKBJLRw4UL9/Oc/1/HjxyVJv/71r/XBBx/oW9/6liTpxIkT6uzsVGlpaeA5TqdTRUVFamlpGfI1/X6/ent7gwoAAACQaJhYDEhCzz33nHp6ejR9+nSlpKTo0qVL2rBhgx599FFJUmdnpyTJ5XIFPc/lcunkyZNDvqbP59O6desi23EAAADAZoxEA0nozTff1BtvvKGGhgZ98sknqq+v10svvaT6+vqgdg6HI+ixMWZQ3YDq6mr19PQESkdHR8T6DwAAANiFkWggCf3gBz/QmjVr9Mgjj0iS7rzzTp08eVI+n0/Lly+X2+2WdGVEOisrK/C8rq6uQaPTA5xOp5xOZ+Q7DwAAANiIkWggCZ07d0633BIc/ikpKYFbXOXm5srtdqupqSmwvL+/X83NzSosLIxqXwEAAIBYwkg0kISWLFmiDRs2aOLEiZo5c6ba2tpUU1Ojp556StKV07grKyvl9XqVl5envLw8eb1epaWlqayszObeAwAAAPYhiQaS0CuvvKLnn39eFRUV6urqUnZ2tsrLy/XCCy8E2lRVVen8+fOqqKhQd3e35s6dq8bGRqWnp9vYcwAAAMBeJNFAEkpPT1dtba1qa2uv28bhcMjj8cjj8UStXwAAAECs45poAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAMBGp0+f1mOPPabx48crLS1Nd999tw4dOhRYboyRx+NRdna2UlNTVVxcrPb2dht7DCQ3kmgAAADAJt3d3VqwYIFGjx6td999V0eOHNHLL7+sW2+9NdBm8+bNqqmp0ZYtW9Ta2iq3262SkhL19fXZ13EgiY2yuwMAAABAstq0aZNycnK0Y8eOQN3kyZMDfxtjVFtbq7Vr12rp0qWSpPr6erlcLjU0NKi8vDzaXQaSHiPRAAAAgE327t2rgoICPfTQQ5owYYJmzZql7du3B5afOHFCnZ2dKi0tDdQ5nU4VFRWppaVlyNf0+/3q7e0NKgDChyQaAAAAsMlnn32muro65eXl6b333tOKFSv0zDPP6PXXX5ckdXZ2SpJcLlfQ81wuV2DZtXw+nzIzMwMlJycnsisBJBmSaAAAAMAmly9f1j333COv16tZs2apvLxc3/ve91RXVxfUzuFwBD02xgyqG1BdXa2enp5A6ejoiFj/gWQUchLN7IEAAMQGjslA/MvKytKMGTOC6u644w6dOnVKkuR2uyVp0KhzV1fXoNHpAU6nUxkZGUEFQPiElEQzeyAAALGBYzKQGBYsWKBjx44F1R0/flyTJk2SJOXm5srtdqupqSmwvL+/X83NzSosLIxqXwFcEdLs3MweCABAbOCYDCSGZ599VoWFhfJ6vXr44Yf18ccfa9u2bdq2bZukK6dxV1ZWyuv1Ki8vT3l5efJ6vUpLS1NZWZnNvQeSU0gj0cweCABAbIjEMVniuAxE25w5c7Rnzx7t2rVL+fn5+tu//VvV1tZq2bJlgTZVVVWqrKxURUWFCgoKdPr0aTU2Nio9Pd3GngPJK6QkmtkDAQCIDZE4JksclwE7LF68WJ9++qkuXLigo0eP6nvf+17QcofDIY/HozNnzujChQtqbm5Wfn6+Tb0FEFISzeyBAADEhkgckyWOywAADCekJJrZAwEAiA2ROCZLHJcBABhOSEk0swcCABAbOCYDAGCPkGbnZvZAAABiA8dkAADsEdJINLMHAonj9OnTeuyxxzR+/HilpaXp7rvv1qFDhwLLjTHyeDzKzs5WamqqiouL1d7ebmOPAVyNYzIAAPYIaSRaujJ74OLFi6+7fGD2QI/HczP9AhBB3d3dWrBggf7sz/5M7777riZMmKDf//73uvXWWwNtNm/erJqaGu3cuVNTp07Viy++qJKSEh07dowv4ECM4JgMAED0hZxEA4h/mzZtUk5Ojnbs2BGomzx5cuBvY4xqa2u1du1aLV26VJJUX18vl8ulhoYGlZeXR7vLAAAAQEwI6XRuAIlh7969Kigo0EMPPaQJEyZo1qxZ2r59e2D5iRMn1NnZqdLS0kCd0+lUUVGRWlpa7OgyAAAAEBNIooEk9Nlnn6murk55eXl67733tGLFCj3zzDN6/fXXJf3xljjX3gbH5XINul3OAL/fr97e3qACAAAAJBpO5waS0OXLl1VQUCCv1ytJmjVrltrb21VXV6fvfve7gXYOhyPoecaYQXUDfD6f1q1bF7lOAwAAADGAkWggCWVlZWnGjBlBdXfccYdOnTolSXK73ZI0aNS5q6tr0Oj0gOrqavX09ARKR0dHBHoOAAAA2IskGkhCCxYs0LFjx4Lqjh8/rkmTJkmScnNz5Xa71dTUFFje39+v5uZmFRYWDvmaTqdTGRkZQQUAAABINJzODSShZ599VoWFhfJ6vXr44Yf18ccfa9u2bdq2bZukK6dxV1ZWyuv1Ki8vT3l5efJ6vUpLS1NZWZnNvQcAAADsQxINJKE5c+Zoz549qq6u1vr165Wbm6va2lotW7Ys0Kaqqkrnz59XRUWFuru7NXfuXDU2NnKPaAAAACQ1kmggSS1evFiLFy++7nKHwyGPxyOPxxO9TgEAAAAxjmuiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAIAY4fP55HA4VFlZGagzxsjj8Sg7O1upqakqLi5We3u7fZ0EkhxJNAAAABADWltbtW3bNt11111B9Zs3b1ZNTY22bNmi1tZWud1ulZSUqK+vz6aeAsmNJBoAAACw2VdffaVly5Zp+/btuu222wL1xhjV1tZq7dq1Wrp0qfLz81VfX69z586poaHBxh4DyYskGgAAALDZypUrtWjRIt1///1B9SdOnFBnZ6dKS0sDdU6nU0VFRWppaRnytfx+v3p7e4MKgPC5qSSaazYAAIgNHJOB+LV792598skn8vl8g5Z1dnZKklwuV1C9y+UKLLuWz+dTZmZmoOTk5IS/00ASG3ESzTUbAADEBo7JQPzq6OjQqlWr9MYbb2js2LHXbedwOIIeG2MG1Q2orq5WT09PoHR0dIS1z0CyG1ESzTUbAADEBo7JQHw7dOiQurq6NHv2bI0aNUqjRo1Sc3OzfvzjH2vUqFGBEehrR527uroGjU4PcDqdysjICCoAwmdESTTXbAAAEBvCeUyWOC4D0Xbffffp008/1eHDhwOloKBAy5Yt0+HDhzVlyhS53W41NTUFntPf36/m5mYVFhba2HMgeY0K9QkD12y0trYOWnajazZOnjw55Ov5fD6tW7cu1G4AAJD0wn1MljguA9GWnp6u/Pz8oLpx48Zp/PjxgfrKykp5vV7l5eUpLy9PXq9XaWlpKisrs6PLQNILaSSaazYAAIgNkTgmSxyXgVhUVVWlyspKVVRUqKCgQKdPn1ZjY6PS09Pt7hqQlEJKorlmA0g8zOgLxKdIHJMljstALNi/f79qa2sDjx0Ohzwej86cOaMLFy6oubl50Og1gOgJKYnmmg0gsTCjLxC/OCYDAGCPkK6J5poNIHFcPaPviy++GKi/dkZfSaqvr5fL5VJDQ4PKy8vt6jKAq3BMBgDAHiO+T/T1cM0GEB/CPaMvgNjDMRkAgPALeXbua+3fvz/o8cA1Gx6P52ZfGkCERGJGX7/fL7/fH3jMbXGA6OOYDABA5IV9JBpAbIvUjL4+n0+ZmZmBkpOTE7Y+AwAAALGCJBpIMpGa0Zfb4gAAACAZ3PTp3ADiy8CMvld78sknNX36dD333HNBM/rOmjVL0h9n9N20adN1X9fpdMrpdEa07wAAAIDdSKKBJMOMvgAAAMDIkUQDGKSqqkrnz59XRUWFuru7NXfuXGb0BQAAAEQSDUDM6AsAAABYxcRiAAAAAABYRBINAAAAAIBFJNEAAAAAAFhEEg0AAAAAgEUk0QAAAAAAWEQSDQAAAACARSTRAAAAAABYRBINAAAAAIBFJNEAAAAAAFhEEg0AAAAAgEUk0QAAAAAAWEQSDQAAAACARSTRAAAAAABYRBINAAAAAIBFJNEAAAAAAFhEEg0AAAAAgEUk0QAAAAAAWEQSDQAAAACARSTRAAAAAABYRBINAAAAAIBFJNEAAAAAAFhEEg0AAAAAgEUk0QAAAAAAWEQSDQAAAACARaPs7gAAAACAxDJ5zTtheZ3PNy4Ky+sA4cRINAAAAAAAFpFEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaRRAMAAAAAYBFJNAAAAAAAFpFEAwAAAABgEUk0AAAAYBOfz6c5c+YoPT1dEyZM0He+8x0dO3YsqI0xRh6PR9nZ2UpNTVVxcbHa29tt6jGAUXZ3AAAAYMDkNe+E7bU+37gobK8FREpzc7NWrlypOXPm6OLFi1q7dq1KS0t15MgRjRs3TpK0efNm1dTUaOfOnZo6dapefPFFlZSU6NixY0pPT7d5DYDkE9JINL+UAQAQGzgmA4lh3759euKJJzRz5kx985vf1I4dO3Tq1CkdOnRI0pU4rq2t1dq1a7V06VLl5+ervr5e586dU0NDg829B5JTSEn0wC9lH330kZqamnTx4kWVlpbq7NmzgTYDv5Rt2bJFra2tcrvdKikpUV9fX9g7DwBAsuKYDCSmnp4eSdLXvvY1SdKJEyfU2dmp0tLSQBun06mioiK1tLQM+Rp+v1+9vb1BBUD4hHQ69759+4Ie79ixQxMmTNChQ4d07733DvqlTJLq6+vlcrnU0NCg8vLy8PUcAIAkxjEZSDzGGK1evVoLFy5Ufn6+JKmzs1OS5HK5gtq6XC6dPHlyyNfx+Xxat25dZDsLJLGbmliMX8qA+MRpoEDiCccxWeK4DNjp6aef1m9+8xvt2rVr0DKHwxH02BgzqG5AdXW1enp6AqWjoyMi/QWS1YiT6FB/KRtYdi2fz6fMzMxAycnJGWmXAFjEaaBAYgnXMVniuAzY5fvf/7727t2r999/X7fffnug3u12S9KguO3q6hoU3wOcTqcyMjKCCoDwGXESzS9lQPxiEhMgsYTrmCxxXAaizRijp59+Wm+//bZ+8YtfKDc3N2h5bm6u3G63mpqaAnX9/f1qbm5WYWFhtLsLQCO8xdXAL2UHDhy47i9lWVlZgfrhfilzOp0j6QaAMAn1NNChrqX0+/3y+/2Bx5wCCkRHOI/JEsdlINpWrlyphoYG/fSnP1V6enpgxDkzM1OpqalyOByqrKyU1+tVXl6e8vLy5PV6lZaWprKyMpt7DySnkEai+aUMSDxcmgHEJ47JQGKoq6tTT0+PiouLlZWVFShvvvlmoE1VVZUqKytVUVGhgoICnT59Wo2NjdwjGrBJSCPR/FIGJJ6B00A/+OCDQctCvTRj9erVgce9vb0k0kAEcUwGEoMxZtg2DodDHo9HHo8n8h0CMKyQkui6ujpJUnFxcVD9jh079MQTT0i68kvZ+fPnVVFRoe7ubs2dO5dfyoAYxaUZQPzimAwAgD1CSqL5pQxIDMYYff/739eePXu0f//+G54GOmvWLEl/PA1006ZNdnQZwDU4JgMAYI8RTSwGIL5xGigAAAAwMiTRQBLiNFAAAABgZEiigSTEaaAAAADAyIR0iysAAAAAAJIZSTQAAAAAABaRRAMAAAAAYBFJNAAAAAAAFpFEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaRRAMAAAAAYBFJNAAAAAAAFpFEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaNsrsDQCyYvOadm36N1P4LOhqGvgAAAACIXYxEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaRRAMAAAAAYBFJNAAAAAAAFpFEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaNsrsDAACEw+Q179jdBQAAkAQYiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACziFlcJLpy3fPl846KwvRYAAAAAxCOSaABIIrH4wxr3dwYAAPEkrpPom/3idVkXpNQwdSbM+FI5PLYRAOBGwnWc4EwswD6x+OMvENdJNID4F86DY/v64rC9FgAAADAUJhYDAAAAAMAiRqLDKNFPL0709QMGsK8DQOhG8tl59aV1d7ywT7doLKfcAgkilM+EoT4Lwi2cny0RG4l+9dVXlZubq7Fjx2r27Nn65S9/Gal/BSBCiGMgMRDLQGIgloHYEJEk+s0331RlZaXWrl2rtrY2/ef//J/14IMP6tSpU5H4dwAigDgGEgOxDCQGYhmIHRE5nbumpkZ/9Vd/pb/+67+WJNXW1uq9995TXV2dfD5fJP7lTYvUaQNAvIrXOI70qUD4I057jw/xGMuxxsq+ntp/QUf//e87nt+n82MGf/6E81TCRJ55PBY/W2JhOxHLN+/afctK3A4lFm/xGAv7aDIJexLd39+vQ4cOac2aNUH1paWlamlpGdTe7/fL7/cHHvf09EiSent7h/1fl/3nbqqvl3VBclz9Wpdv6vWQ3C71X9DAXnvJf06XTej709X7ZG9vry6NuXTdtgMxYowJ+f8MJ9Q4lkYeyzcbx0GvRUwjwqzGudVYjmQcS9GL5bP9Z6ULV/5O1tizsm9Y+W5jVbg+O+3uU7x8bg+3nWItlolja0b63S1ccRPO70DhjOVwCWX9ovFZENY4NmF2+vRpI8n86le/CqrfsGGDmTp16qD2P/rRj4wkCoUywtLR0RHuMA45jollCuXmSiTimFimUKJfYiWWiWMKZeTFShxHbHZuh8MR9NgYM6hOkqqrq7V69erA48uXL+tf//VfNX78+EHte3t7lZOTo46ODmVkZESm4wjCNo8+q9vcGKO+vj5lZ2dHrC9W41gilmMd2zz6rGzzaMSxFLlYHpCI+1eirVOirY8UW+sUa7FMHF9fMqwn6zgyocRx2JPor3/960pJSVFnZ2dQfVdXl1wu16D2TqdTTqczqO7WW2+94f/IyMhI2B0iVrHNo8/KNs/MzIzI/w41jiViOV6wzaNvuG0eqTiWohfLAxJx/0q0dUq09ZFiZ51iKZaJ4+Elw3qyjqGzGsdhn517zJgxmj17tpqamoLqm5qaVFhYGO5/ByACiGMgMRDLQGIgloHYEpHTuVevXq3HH39cBQUFmj9/vrZt26ZTp05pxYoVkfh3ACKAOAYSA7EMJAZiGYgdEUmi//Iv/1J/+MMftH79ep05c0b5+fn62c9+pkmTJt3U6zqdTv3oRz8adHoKIodtHn2xss0jFcdS7KxjMmGbR1+sbPNIxvKAWFnXcEq0dUq09ZESc51uJNKxnCzbMxnWk3WMPIcxEZqLHwAAAACABBP2a6IBAAAAAEhUJNEAAAAAAFhEEg0AAAAAgEUk0QAAAAAAWBRzSfSrr76q3NxcjR07VrNnz9Yvf/nLG7Zvbm7W7NmzNXbsWE2ZMkVbt26NUk8TRyjbfP/+/XI4HIPKv/zLv0Sxx/HtwIEDWrJkibKzs+VwOPSTn/xk2OfE235OHNuDWI6uRI7lSMTwW2+9pRkzZsjpdGrGjBnas2dPpLo/pHCv086dO4eMoQsXLkRyNYKEsk5nzpxRWVmZpk2bpltuuUWVlZVDtrPzfQr3+sTCe2S3RIzlayVibF8r0WJ9KHEX/yaG7N6924wePdps377dHDlyxKxatcqMGzfOnDx5csj2n332mUlLSzOrVq0yR44cMdu3bzejR482//RP/xTlnsevULf5+++/bySZY8eOmTNnzgTKxYsXo9zz+PWzn/3MrF271rz11ltGktmzZ88N28fbfk4c24NYjr5EjeVIxHBLS4tJSUkxXq/XHD161Hi9XjNq1Cjz0Ucfxe067dixw2RkZATFz5kzZ6KyPsaEvk4nTpwwzzzzjKmvrzd33323WbVq1aA2dr5PkVgfu98juyViLF8rEWP7WokW60OJx/iPqST6T//0T82KFSuC6qZPn27WrFkzZPuqqiozffr0oLry8nIzb968iPUx0YS6zQe+eHd3d0ehd4nPyhfveNvPiWN7EMv2SqRYjkQMP/zww+Yv/uIvgto88MAD5pFHHglTr28sEuu0Y8cOk5mZGfa+WhXqOl2tqKhoyC+ddr5PkVgfu98juyViLF8rEWP7WokW60OJx/iPmdO5+/v7dejQIZWWlgbVl5aWqqWlZcjnfPjhh4PaP/DAAzp48KD+7d/+LWJ9TRQj2eYDZs2apaysLN133316//33I9nNpBdP+zlxbA9iOT7Ew74eqRi+Xpvh9s9wiOTn0ldffaVJkybp9ttv1+LFi9XW1hb+FRjCzcT8jdj1PkVqfST73iO7JWIsXysRY/taiRbrQ4nX+I+ZJPrLL7/UpUuX5HK5gupdLpc6OzuHfE5nZ+eQ7S9evKgvv/wyYn1NFCPZ5llZWdq2bZveeustvf3225o2bZruu+8+HThwIBpdTkrxtJ8Tx/YgluNDPOzrkYrh67W53muGU6TWafr06dq5c6f27t2rXbt2aezYsVqwYIF+97vfRWZFrjKSdbLCrvcpUutj53tkt0SM5WslYmxfK9FifSjxGv+jwvIqYeRwOIIeG2MG1Q3Xfqh6XF8o23zatGmaNm1a4PH8+fPV0dGhl156Sffee29E+5nM4m0/J47tQSzHvnjZ1yMRw6G+ZriFe53mzZunefPmBZYvWLBA99xzj1555RX9+Mc/Dle3bygS29TO9ync/zsW3iO7JWIsXysRY/taiRbrQ4m3+I+Zkeivf/3rSklJGfSLQ1dX16BfJga43e4h248aNUrjx4+PWF8TxUi2+VDmzZuXFL/q2iWe9nPi2B7EcnyIh309UjF8vTah7J8jFa3PpVtuuUVz5syJSgyFK+avZdf7FKn1uVY03yO7JWIsXysRY/taiRbrQ4nX+I+ZJHrMmDGaPXu2mpqaguqbmppUWFg45HPmz58/qH1jY6MKCgo0evToiPU1UYxkmw+lra1NWVlZ4e4e/l087efEsT2I5fgQD/t6pGL4em1C2T9HKlqfS8YYHT58OCoxFK6Yv5Zd71Ok1uda0XyP7JaIsXytRIztayVarA8lbuM/YlOWjcDA9OavvfaaOXLkiKmsrDTjxo0zn3/+uTHGmDVr1pjHH3880H5gmvpnn33WHDlyxLz22msxebuQWBbqNv/7v/97s2fPHnP8+HHz29/+1qxZs8ZIMm+99ZZdqxB3+vr6TFtbm2lrazOSTE1NjWlrawtM4x/v+zlxbA9iOfoSNZYjEcO/+tWvTEpKitm4caM5evSo2bhxoy23uArnOnk8HrNv3z7z+9//3rS1tZknn3zSjBo1yvzzP/9zTK6TMSawv86ePduUlZWZtrY2097eHlhu5/sUifWx+z2yWyLG8rUSMbavlWixPpR4jP+YSqKNMeYf/uEfzKRJk8yYMWPMPffcY5qbmwPLli9fboqKioLa79+/38yaNcuMGTPGTJ482dTV1UW5x/EvlG2+adMm8yd/8idm7Nix5rbbbjMLFy4077zzjg29jl8Dtxa6tixfvtwYkxj7OXFsD2I5uhI5liMRw//4j/9opk2bZkaPHm2mT58e9R9swr1OlZWVZuLEiWbMmDHmG9/4hiktLTUtLS3RWJWAUNdpqP110qRJQW3sfJ/CvT6x8B7ZLRFj+VqJGNvXSrRYH0q8xb/j3zsBAAAAAACGETPXRAMAAAAAEOtIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBpIQhcvXtQPf/hD5ebmKjU1VVOmTNH69et1+fLlQBtjjDwej7Kzs5Wamqri4mK1t7fb2GsAAADAfqPs7sC1Ll++rC+++ELp6elyOBx2dweIWcYY9fX1KTs7W7fcEtrvYZs2bdLWrVtVX1+vmTNn6uDBg3ryySeVmZmpVatWSZI2b96smpoa7dy5U1OnTtWLL76okpISHTt2TOnp6cP+D2IZGN7NxHG0EMvA8GI9loljYHghxbGJMR0dHUYShUKxWDo6OkKOs0WLFpmnnnoqqG7p0qXmscceM8YYc/nyZeN2u83GjRsDyy9cuGAyMzPN1q1biWUKJcxlJHEcLcQyhWK9xGosE8cUivViJY5jbiR6YISro6NDGRkZ1213tv+ssl/OliR98T++0Lgx46LSv7h29qyUfWWb6YsvpHFss2iI1L7a29urnJwcS6PC11q4cKG2bt2q48ePa+rUqfr1r3+tDz74QLW1tZKkEydOqLOzU6WlpYHnOJ1OFRUVqaWlReXl5YNe0+/3y+/3Bx4bYyQNH8uRxmdFkrPpc8/qfnczcRwtVo/L4ULMIiJG+FmQKLFsJY5jMvb47pqQYnJfU2hxHHNJ9MApJhkZGTc8WKf0p0hjFWgbKxs/pqWk/PHvjAw+iKIk0vvqSE7Leu6559TT06Pp06crJSVFly5d0oYNG/Too49Kkjo7OyVJLpcr6Hkul0snT54c8jV9Pp/WrVs3qH64WI40PiuSnE2fe6Hud7F8eqXV43K4ELOIiBF+FiRKLFuJ45iMPb67JqSY3NeuYiWOY++iDQAR9+abb+qNN95QQ0ODPvnkE9XX1+ull15SfX19ULtrP0SMMdf9YKmurlZPT0+gdHR0RKz/AAAAgF1ibiQaQOT94Ac/0Jo1a/TII49Iku68806dPHlSPp9Py5cvl9vtlnRlRDorKyvwvK6urkGj0wOcTqecTmfkOw8AAADYiJFoIAmdO3du0KyDKSkpgVtc5ebmyu12q6mpKbC8v79fzc3NKiwsjGpfAQAAgFhCEg0koSVLlmjDhg1655139Pnnn2vPnj2qqanRf/kv/0XSldO4Kysr5fV6tWfPHv32t7/VE088obS0NJWVldncewAS93sHAMAunM4NJKFXXnlFzz//vCoqKtTV1aXs7GyVl5frhRdeCLSpqqrS+fPnVVFRoe7ubs2dO1eNjY0xO/MokGyicb93AAAwGEk0kITS09NVW1sbuKXVUBwOhzwejzweT9T6BcC6Dz/8UN/+9re1aNEiSdLkyZO1a9cuHTx4UNKVUeja2lqtXbtWS5culSTV19fL5XKpoaFhyFvVAQCA4XE6NwAAcWjhwoX6+c9/ruPHj0tS4H7v3/rWtyQNf7/36/H7/ert7Q0qAADgjxJiJPqOF/bploGbjY3A5xsXhbE3AIB4N3nNOzf1/Mu6IKWGqTPXEYn7vUvXv+c7EG+ujuPU/gs6+u9/3/H8Pp0fY+17YzRiORbd7Hdrie/XSGyMRAMAEIcicb93iXu+AwAwnIQYiQYAINlE4n7vEvd8BwBgOIxEAwAQh7jfOwAA9mAkGgCAODRwv/eJEydq5syZamtrU01NjZ566ilJwfd7z8vLU15enrxeL/d7BwDgJpFEAwAQh7jfOwAA9iCJBgAgDnG/dwAA7ME10QAAAAAAWBRyEn369Gk99thjGj9+vNLS0nT33Xfr0KFDgeXGGHk8HmVnZys1NVXFxcVqb28Pa6cBAAAAALBDSEl0d3e3FixYoNGjR+vdd9/VkSNH9PLLL+vWW28NtNm8ebNqamq0ZcsWtba2yu12q6SkRH19feHuOwAAAAAAURXSNdGbNm1STk6OduzYEaibPHly4G9jjGpra7V27VotXbpUklRfXy+Xy6WGhgaVl5eHp9cAAAAAANggpJHovXv3qqCgQA899JAmTJigWbNmafv27YHlJ06cUGdnp0pLSwN1TqdTRUVFamlpCV+vAQAAAACwQUhJ9Geffaa6ujrl5eXpvffe04oVK/TMM8/o9ddflyR1dnZKklwuV9DzXC5XYNm1/H6/ent7gwoAAAAAALEopNO5L1++rIKCAnm9XknSrFmz1N7errq6On33u98NtHM4HEHPM8YMqhvg8/m0bt26UPsNAAAAAEDUhTQSnZWVpRkzZgTV3XHHHTp16pQkye12S9KgUeeurq5Bo9MDqqur1dPTEygdHR2hdAkAAACIWxcvXtQPf/hD5ebmKjU1VVOmTNH69et1+fLlQBvufgPElpCS6AULFujYsWNBdcePH9ekSZMkSbm5uXK73Wpqagos7+/vV3NzswoLC4d8TafTqYyMjKACAAAAJINNmzZp69at2rJli44eParNmzfr7/7u7/TKK68E2nD3GyC2hHQ697PPPqvCwkJ5vV49/PDD+vjjj7Vt2zZt27ZN0pXTuCsrK+X1epWXl6e8vDx5vV6lpaWprKwsIisAAAAAxKsPP/xQ3/72t7Vo0SJJV+58s2vXLh08eFASd78BYlFII9Fz5szRnj17tGvXLuXn5+tv//ZvVVtbq2XLlgXaVFVVqbKyUhUVFSooKNDp06fV2Nio9PT0sHceAAAAiGcLFy7Uz3/+cx0/flyS9Otf/1offPCBvvWtb0ka2d1vmLgXiKyQRqIlafHixVq8ePF1lzscDnk8Hnk8npvpFwAAAJDwnnvuOfX09Gj69OlKSUnRpUuXtGHDBj366KOSbnz3m5MnTw75mkzcC0RWSCPRAAAAAMLnzTff1BtvvKGGhgZ98sknqq+v10svvaT6+vqgdqHc/YaJe4HICnkkGgAAAEB4/OAHP9CaNWv0yCOPSJLuvPNOnTx5Uj6fT8uXLw+6+01WVlbgeTe6+43T6ZTT6Yx854EkxUg0AAAAYJNz587plluCv5KnpKQEbnE1krvfAIgsRqIBAAAAmyxZskQbNmzQxIkTNXPmTLW1tammpkZPPfWUJO5+A8QikmgAAADAJq+88oqef/55VVRUqKurS9nZ2SovL9cLL7wQaFNVVaXz58+roqJC3d3dmjt3Lne/AWxEEg0AAADYJD09XbW1taqtrb1uG+5+A8QWrokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwKKQkmiPxyOHwxFU3G53YLkxRh6PR9nZ2UpNTVVxcbHa29vD3mkAN+/06dN67LHHNH78eKWlpenuu+/WoUOHAsuJZwAAAGCwkEeiZ86cqTNnzgTKp59+Gli2efNm1dTUaMuWLWptbZXb7VZJSYn6+vrC2mkAN6e7u1sLFizQ6NGj9e677+rIkSN6+eWXdeuttwbaEM8AAADAYKNCfsKoUUGjzwOMMaqtrdXatWu1dOlSSVJ9fb1cLpcaGhpUXl5+870FEBabNm1STk6OduzYEaibPHly4G/iGQAAABhayCPRv/vd75Sdna3c3Fw98sgj+uyzzyRJJ06cUGdnp0pLSwNtnU6nioqK1NLSct3X8/v96u3tDSoAImvv3r0qKCjQQw89pAkTJmjWrFnavn17YPlI4plYBgAAQDIIKYmeO3euXn/9db333nvavn27Ojs7VVhYqD/84Q/q7OyUJLlcrqDnuFyuwLKh+Hw+ZWZmBkpOTs4IVgNAKD777DPV1dUpLy9P7733nlasWKFnnnlGr7/+uiSNKJ6JZQAAACSDkJLoBx98UP/1v/5X3Xnnnbr//vv1zjvvSLpymucAh8MR9BxjzKC6q1VXV6unpydQOjo6QukSgBG4fPmy7rnnHnm9Xs2aNUvl5eX63ve+p7q6uqB2ocQzsQwAAIBkcFO3uBo3bpzuvPNO/e53vwtcJ33tKFVXV9eg0ayrOZ1OZWRkBBUAkZWVlaUZM2YE1d1xxx06deqUJI0onollIPqYZR8AgOi7qSTa7/fr6NGjysrKUm5urtxut5qamgLL+/v71dzcrMLCwpvuKIDwWbBggY4dOxZUd/z4cU2aNEmSiGcgDjDLPgAA9ghpdu7/+T//p5YsWaKJEyeqq6tLL774onp7e7V8+XI5HA5VVlbK6/UqLy9PeXl58nq9SktLU1lZWaT6D2AEnn32WRUWFsrr9erhhx/Wxx9/rG3btmnbtm2SRDwDcYBZ9gEAsEdISfT//b//V48++qi+/PJLfeMb39C8efP00UcfBUavqqqqdP78eVVUVKi7u1tz585VY2Oj0tPTI9J5ACMzZ84c7dmzR9XV1Vq/fr1yc3NVW1urZcuWBdoQz0Bs27t3rx544AE99NBDam5u1n/8j/9RFRUV+t73vidp+Fn2r5dE+/1++f3+wGNm2gcAIFhISfTu3btvuNzhcMjj8cjj8dxMnwBEweLFi7V48eLrLieegdg2MMv+6tWr9Td/8zf6+OOP9cwzz8jpdOq73/3uDWfZP3ny5HVf1+fzad26dRHtOwAA8eymrokGAAD2iMQs+xIz7QMAMBySaAAA4lAkZtmXmGkfAIDhkEQDABCHmGUfAAB7hHRNNAAAiA3Msg8AgD1IogEAiEPMsg8AgD1IogEAiFPMsg8AQPRxTTQAAAAAABaRRAMAAAAAYBFJNAAAAGCj06dP67HHHtP48eOVlpamu+++W4cOHQosN8bI4/EoOztbqampKi4uVnt7u409BpIbSTQAAABgk+7ubi1YsECjR4/Wu+++qyNHjujll1/WrbfeGmizefNm1dTUaMuWLWptbZXb7VZJSYn6+vrs6ziQxJhYDAAAALDJpk2blJOTox07dgTqJk+eHPjbGKPa2lqtXbtWS5culSTV19fL5XKpoaFB5eXl0e4ykPQYiQYAAABssnfvXhUUFOihhx7ShAkTNGvWLG3fvj2w/MSJE+rs7FRpaWmgzul0qqioSC0tLXZ0GUh6JNEAAACATT777DPV1dUpLy9P7733nlasWKFnnnlGr7/+uiSps7NTkuRyuYKe53K5Asuu5ff71dvbG1QAhA+ncwMAAAA2uXz5sgoKCuT1eiVJs2bNUnt7u+rq6vTd73430M7hcAQ9zxgzqG6Az+fTunXrItdpIMkxEg0AAADYJCsrSzNmzAiqu+OOO3Tq1ClJktvtlqRBo85dXV2DRqcHVFdXq6enJ1A6Ojoi0HMgeZFEAwAAADZZsGCBjh07FlR3/PhxTZo0SZKUm5srt9utpqamwPL+/n41NzersLBwyNd0Op3KyMgIKgDCh9O5AQAAAJs8++yzKiwslNfr1cMPP6yPP/5Y27Zt07Zt2yRdOY27srJSXq9XeXl5ysvLk9frVVpamsrKymzuPZCcSKIBAAAAm8yZM0d79uxRdXW11q9fr9zcXNXW1mrZsmWBNlVVVTp//rwqKirU3d2tuXPnqrGxUenp6Tb2HEheJNEAAACAjRYvXqzFixdfd7nD4ZDH45HH44lepwBcF9dEAwAAAABg0U0l0T6fL3CdxgBjjDwej7Kzs5Wamqri4mK1t7ffbD8BAAAAALDdiJPo1tZWbdu2TXfddVdQ/ebNm1VTU6MtW7aotbVVbrdbJSUl6uvru+nOAgAAAABgpxEl0V999ZWWLVum7du367bbbgvUG2NUW1urtWvXaunSpcrPz1d9fb3OnTunhoaGsHUaAAAAAAA7jCiJXrlypRYtWqT7778/qP7EiRPq7OxUaWlpoM7pdKqoqEgtLS1Dvpbf71dvb29QAQAAAAAgFoU8O/fu3bv1ySefqLW1ddCyzs5OSZLL5Qqqd7lcOnny5JCv5/P5tG7dulC7AQAAAABA1IU0Et3R0aFVq1bpjTfe0NixY6/bzuFwBD02xgyqG1BdXa2enp5A6ejoCKVLAAAAAABETUgj0YcOHVJXV5dmz54dqLt06ZIOHDigLVu26NixY5KujEhnZWUF2nR1dQ0anR7gdDrldDpH0ncAAAAAAKIqpJHo++67T59++qkOHz4cKAUFBVq2bJkOHz6sKVOmyO12q6mpKfCc/v5+NTc3q7CwMOydBwAAAAAgmkIaiU5PT1d+fn5Q3bhx4zR+/PhAfWVlpbxer/Ly8pSXlyev16u0tDSVlZWFr9cAAAAAANgg5InFhlNVVaXz58+roqJC3d3dmjt3rhobG5Wenh7ufwUAAAAAQFTddBK9f//+oMcOh0Mej0cej+dmXxoAAAAAgJgyovtEAwAAAACQjEiiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBpIcj6fTw6HQ5WVlYE6Y4w8Ho+ys7OVmpqq4uJitbe329dJAAAAIEaQRANJrLW1Vdu2bdNdd90VVL9582bV1NRoy5Ytam1tldvtVklJifr6+mzqKQAAABAbSKKBJPXVV19p2bJl2r59u2677bZAvTFGtbW1Wrt2rZYuXar8/HzV19fr3LlzamhosLHHAAAAgP1IooEktXLlSi1atEj3339/UP2JEyfU2dmp0tLSQJ3T6VRRUZFaWlqu+3p+v1+9vb1BBQAAAEg0JNFAEtq9e7c++eQT+Xy+Qcs6OzslSS6XK6je5XIFlg3F5/MpMzMzUHJycsLbaQA3xPwGAABExyi7OxALJq95Jyyv8/nGRWF5HSCSOjo6tGrVKjU2Nmrs2LHXbedwOIIeG2MG1V2turpaq1evDjzu7e0lkQaiZLj5DXbu3KmpU6fqxRdfVElJiY4dO6b09HSbegsAQHxjJBpIMocOHVJXV5dmz56tUaNGadSoUWpubtaPf/xjjRo1KjACfe2oc1dX16DR6as5nU5lZGQEFQCRx/wGAABEF0k0kGTuu+8+ffrppzp8+HCgFBQUaNmyZTp8+LCmTJkit9utpqamwHP6+/vV3NyswsJCG3sOYCjMbwAAQHRxOjeQZNLT05Wfnx9UN27cOI0fPz5QX1lZKa/Xq7y8POXl5cnr9SotLU1lZWV2dBnAdQzMb9Da2jpo2Y3mNzh58uR1X9Pn82ndunXh7SgAAAmEJBrAIFVVVTp//rwqKirU3d2tuXPnqrGxkWsogRjC/AYAANgjpNO56+rqdNdddwWud5w/f77efffdwHJmAQXi0/79+1VbWxt47HA45PF4dObMGV24cEHNzc2DRq8B2Iv5DQAAsEdISfTtt9+ujRs36uDBgzp48KD+/M//XN/+9rcDifLALKBbtmxRa2ur3G63SkpK1NfXF5HOAwCQrJjfAAAAe4R0OveSJUuCHm/YsEF1dXX66KOPNGPGjKBZQCWpvr5eLpdLDQ0NKi8vD1+vAQBIcsxvAACAPUY8O/elS5e0e/dunT17VvPnzx/xLKAAACAyqqqqVFlZqYqKChUUFOj06dPMbwDEOJ/PJ4fDocrKykAdl0wCsSXkicU+/fRTzZ8/XxcuXNB/+A//QXv27NGMGTMCiXKos4D6/X75/f7AY26lAQDAyOzfvz/o8cD8Bh6Px5b+AAhNa2urtm3bprvuuiuofuCSyZ07d2rq1Kl68cUXVVJSomPHjvGjGGCDkEeip02bpsOHD+ujjz7Sf//v/13Lly/XkSNHAstDnQXU5/MpMzMzUJgBFAAAAMnmq6++0rJly7R9+3bddtttgXpjTNAlk/n5+aqvr9e5c+fU0NBgY4+B5BVyEj1mzBj9p//0n1RQUCCfz6dvfvOb+l//63/J7XZLCn0W0OrqavX09ARKR0dHqF0CAAAA4trKlSu1aNEi3X///UH1I7lk0u/3q7e3N6gACJ8RXxM9wBgjv9+v3NzcEc0Cyq00AAAAkMx2796tTz75RD6fb9CygQGqoS6ZvHbwagBnegKRFdI10X/zN3+jBx98UDk5Oerr69Pu3bu1f/9+7du3LzABArOAAgAAANZ0dHRo1apVamxs1NixY6/bLpRLJqurq7V69erA497eXhJpIIxCSqL/3//7f3r88cd15swZZWZm6q677tK+fftUUlIi6cosoOfPn1dFRYW6u7s1d+5cZgEFAAAAruPQoUPq6urS7NmzA3WXLl3SgQMHtGXLFh07dkzSlRHprKysQJsbXTLpdDrldDoj23EgiYWURL/22ms3XM4soAAAAIB19913nz799NOguieffFLTp0/Xc889pylTpgQumZw1a5akP14yuWnTJju6DCS9kG9xBQAAACA80tPTlZ+fH1Q3btw4jR8/PlDPJZNAbCGJBgAAAGIYl0wCsYUkGgAAAIgh+/fvD3rMJZNAbLnpW1wBAAAAAJAsSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0iiAQAAAACwiCQaAAAAAACLSKIBAAAAALCIJBoAAAAAAItIogEAAAAAsIgkGgAAAAAAi0JKon0+n+bMmaP09HRNmDBB3/nOd3Ts2LGgNsYYeTweZWdnKzU1VcXFxWpvbw9rpwEAAAAAsENISXRzc7NWrlypjz76SE1NTbp48aJKS0t19uzZQJvNmzerpqZGW7ZsUWtrq9xut0pKStTX1xf2zgMAAAAAEE2jQmm8b9++oMc7duzQhAkTdOjQId17770yxqi2tlZr167V0qVLJUn19fVyuVxqaGhQeXl5+HoOAAAAAECU3dQ10T09PZKkr33ta5KkEydOqLOzU6WlpYE2TqdTRUVFamlpuZl/BQAAAACA7UIaib6aMUarV6/WwoULlZ+fL0nq7OyUJLlcrqC2LpdLJ0+eHPJ1/H6//H5/4HFvb+9IuwQAAAAAQESNeCT66aef1m9+8xvt2rVr0DKHwxH02BgzqG6Az+dTZmZmoOTk5Iy0SwAAAAAARNSIkujvf//72rt3r95//33dfvvtgXq32y3pjyPSA7q6ugaNTg+orq5WT09PoHR0dIykSwAAAAAARFxISbQxRk8//bTefvtt/eIXv1Bubm7Q8tzcXLndbjU1NQXq+vv71dzcrMLCwiFf0+l0KiMjI6gAAAAAABCLQromeuXKlWpoaNBPf/pTpaenB0acMzMzlZqaKofDocrKSnm9XuXl5SkvL09er1dpaWkqKyuLyAoAAAAAABAtISXRdXV1kqTi4uKg+h07duiJJ56QJFVVVen8+fOqqKhQd3e35s6dq8bGRqWnp4elwwAAAAAA2CWkJNoYM2wbh8Mhj8cjj8cz0j4BAAAAABCTbuo+0QDik8/n05w5c5Senq4JEyboO9/5jo4dOxbUxhgjj8ej7Oxspaamqri4WO3t7Tb1GAAAAIgNJNFAEmpubtbKlSv10UcfqampSRcvXlRpaanOnj0baLN582bV1NRoy5Ytam1tldvtVklJifr6+mzsOQAAAGAvkmggCe3bt09PPPGEZs6cqW9+85vasWOHTp06pUOHDkm6MgpdW1urtWvXaunSpcrPz1d9fb3OnTunhoYGm3sPQOKMEgAA7EISDUA9PT2SpK997WuSpBMnTqizs1OlpaWBNk6nU0VFRWppaRnyNfx+v3p7e4MKgMjhjBIAAOxBEg0kOWOMVq9erYULFyo/P1+SArevc7lcQW1dLldg2bV8Pp8yMzMDJScnJ7IdB5IcZ5QAAGAPkmggyT399NP6zW9+o127dg1a5nA4gh4bYwbVDaiurlZPT0+gdHR0RKS/AIYWjjNKJM4qAQBgOCTRQBL7/ve/r7179+r999/X7bffHqh3u92SNGjUuaura9Do9ACn06mMjIygAiA6wnVGicRZJUC0Mb8BEH9IooEkZIzR008/rbffflu/+MUvlJubG7Q8NzdXbrdbTU1Ngbr+/n41NzersLAw2t0FMIxwnVEicVYJEG3MbwDEn1F2dwBA9K1cuVINDQ366U9/qvT09MCoVGZmplJTU+VwOFRZWSmv16u8vDzl5eXJ6/UqLS1NZWVlNvcewNUGzig5cODAdc8oycrKCtTf6IwS6cpZJU6nM3IdBhBk3759QY937NihCRMm6NChQ7r33nsHzW8gSfX19XK5XGpoaFB5ebkd3QaSGiPRQBKqq6tTT0+PiouLlZWVFShvvvlmoE1VVZUqKytVUVGhgoICnT59Wo2NjUpPT7ex5wAGcEYJkJjCNb8BgMhhJBpIQsaYYds4HA55PB55PJ7IdwhAyDijBEg8oc5vcPLkySFfx+/3y+/3Bx4zQSAQXiTRAADEobq6OklScXFxUP2OHTv0xBNPSLpyRsn58+dVUVGh7u5uzZ07lzNKgBg2ML/BBx98MGhZKPMb+Hw+rVu3LiJ9BEASDQBAXOKMEiCxhHN+g+rqaq1evTrwuLe3l5n2gTDimmgAAADAJpGY34DbTgKRxUg0AAAAYBPmNwDiD0k0AAAAYBPmNwDiD0k0AAAAYBPmNwDiD9dEAwAAAABgEUk0AAAAAAAWkUQDAAAAAGARSTQAAAAAABaFnEQfOHBAS5YsUXZ2thwOh37yk58ELTfGyOPxKDs7W6mpqSouLlZ7e3u4+gsAAAAAgG1CTqLPnj2rb37zm9qyZcuQyzdv3qyamhpt2bJFra2tcrvdKikpUV9f3013FgAAAAAAO4V8i6sHH3xQDz744JDLjDGqra3V2rVrtXTpUklSfX29XC6XGhoaVF5efnO9BQAAAADARmG9T/SJEyfU2dmp0tLSQJ3T6VRRUZFaWlqGTKL9fr/8fn/gcW9vbzi7BAAAACDKJq9556ZfI7X/go6GoS9AuIV1YrHOzk5JksvlCqp3uVyBZdfy+XzKzMwMlJycnHB2CQAAAACAsInI7NwOhyPosTFmUN2A6upq9fT0BEpHR0ckugQAAAAAwE0L6+ncbrdb0pUR6aysrEB9V1fXoNHpAU6nU06nM5zdAAAAAAAgIsKaROfm5srtdqupqUmzZs2SJPX396u5uVmbNm0K578CACDIUNffXX093R3P79P5MWOj2ykAAJBwQk6iv/rqK/2f//N/Ao9PnDihw4cP62tf+5omTpyoyspKeb1e5eXlKS8vT16vV2lpaSorKwtrxwEAAAAAiLaQk+iDBw/qz/7szwKPV69eLUlavny5du7cqaqqKp0/f14VFRXq7u7W3Llz1djYqPT09PD1GgAAAAAAG4ScRBcXF8sYc93lDodDHo9HHo/nZvoFAAAAAEDMicjs3AAAAAAAJCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsCut9ogEAAICbMdQ93wEgljASDQAAAACARSTRAAAAAABYRBINAAAAAIBFJNEAAAAAAFhEEg0AAAAAgEUk0QAAAAAAWMQtrgAgDoTrli+fb1wUltcBAABIViTRYRTO+xryRTc+DbUPXNYFKfXK33e8sE+3aOywr8P7DwCIN9zfGUCy4HRuAAAAAAAsYiQaQMLgTAAAAABEGiPRAAAAAABYxEg0ACSRWLxmkZF/AAAQT0iiAQDATQvXDzTt64vD8jrhxI9PABC66312hnqpXSx+3pFExyhuZwMAAAAAsYckGoCtYnGEhx+xgMQQi58v4cLnFADYJ2ITi7366qvKzc3V2LFjNXv2bP3yl7+M1L8CECHEMZAYiGUgMRDLQGyIyEj0m2++qcrKSr366qtasGCB/vf//t968MEHdeTIEU2cODES/xJRwK/eyYU4BhIDsQwkBmIZiB0RSaJramr0V3/1V/rrv/5rSVJtba3ee+891dXVyefzReJfAggz4hjRksin3MaCeIvlO17YF/K93TFyxF/8iLdYDrc7nt+n82Nu7vMgXAM5DCxFVyxu77An0f39/Tp06JDWrFkTVF9aWqqWlpZB7f1+v/x+f+BxT0+PJKm3t/eG/+ds/1npwpW/L/vPSbp8cx1PUEHb8ezZqxdIly6F9FpXtnOY+5RghtpGl3VBcly9fPh91co2GmhjjAmpj1aEGsfSyGM5XPvVdV9/BNs/XMK5r0d6OyWqS/0XNPAuXPKf02UTnff/6v2ut7dXl8YM/XkbyTiW4jOW7YxZJK6RfhbEayyPJI5j8bt1uD/Dw3Vc5juxNdfbTnZ9zg+3vUOKYxNmp0+fNpLMr371q6D6DRs2mKlTpw5q/6Mf/chIolAoIywdHR3hDuOQ45hYplBurkQijollCiX6JVZimTimUEZerMRxxGbndjgcQY+NMYPqJKm6ulqrV68OPL58+bL+9V//VePHjx+y/YDe3l7l5OSoo6NDGRkZ4eu4zRJ1vSTWLdyMMerr61N2dnbE/ofVOJasx3Ii7wexjO0efVa2eTTiWCKWEwXb3B7xGMsj+X7N/hUbeB/sE0ochz2J/vrXv66UlBR1dnYG1Xd1dcnlcg1q73Q65XQ6g+puvfVWy/8vIyMjIXewRF0viXULp8zMzIi8bqhxLIUey4m8H8Qytnv0DbfNIxXHErGcqNjm9oinWL6Z79fsX7GB98EeVuM47Le4GjNmjGbPnq2mpqag+qamJhUWFob73wGIAOIYSAzEMpAYiGUgtkTkdO7Vq1fr8ccfV0FBgebPn69t27bp1KlTWrFiRST+HYAIII6BxEAsA4mBWAZiR0SS6L/8y7/UH/7wB61fv15nzpxRfn6+fvazn2nSpElh+x9Op1M/+tGPBp2qEu8Sdb0k1i3eRCqOE3FbxQO2e/TFyjYnlhMH29wesbLdI/39OlbWM9nxPsQHhzERmosfAAAAAIAEE/ZrogEAAAAASFQk0QAAAAAAWEQSDQAAAACARSTRAAAAAABYFDNJ9Kuvvqrc3FyNHTtWs2fP1i9/+csbtm9ubtbs2bM1duxYTZkyRVu3bh3U5q233tKMGTPkdDo1Y8YM7dmzJ1Ldv6Fwr9vOnTvlcDgGlQsXLkRyNQYJZb3OnDmjsrIyTZs2TbfccosqKyuHbBeP75mVdYuV9yxaIhHPGF4o233//v1D7pP/8i//EsUex7cDBw5oyZIlys7OlsPh0E9+8pNhnxNv+zqxHH3EcXQlQxxfjZiODZH4Do0oMzFg9+7dZvTo0Wb79u3myJEjZtWqVWbcuHHm5MmTQ7b/7LPPTFpamlm1apU5cuSI2b59uxk9erT5p3/6p0CblpYWk5KSYrxerzl69Kjxer1m1KhR5qOPPorWahljIrNuO3bsMBkZGebMmTNBJZpCXa8TJ06YZ555xtTX15u7777brFq1alCbeH3PrKxbLLxn0RKJfR7DC3W7v//++0aSOXbsWNA+efHixSj3PH797Gc/M2vXrjVvvfWWkWT27Nlzw/bxtq8Ty9FHHEdfosfx1Yjp2BCJ75mIvphIov/0T//UrFixIqhu+vTpZs2aNUO2r6qqMtOnTw+qKy8vN/PmzQs8fvjhh81f/MVfBLV54IEHzCOPPBKmXlsTiXXbsWOHyczMDHtfQxHqel2tqKhoyA+AeH3Prna9dYuF9yxaIrHPY3ihbveBL9/d3d1R6F3is/LlO972dWI5+ohjeyViHF+NmI4Nkfieieiz/XTu/v5+HTp0SKWlpUH1paWlamlpGfI5H3744aD2DzzwgA4ePKh/+7d/u2Gb671mJERq3STpq6++0qRJk3T77bdr8eLFamtrC/8KXMdI1suKeH3PrLLzPYuWSO7zuL6b2W9nzZqlrKws3XfffXr//fcj2c2kF0/7OrEcfcRxfIjX/ZyYjg2R/J6J6LI9if7yyy916dIluVyuoHqXy6XOzs4hn9PZ2Tlk+4sXL+rLL7+8YZvrvWYkRGrdpk+frp07d2rv3r3atWuXxo4dqwULFuh3v/tdZFbkGiNZLyvi9T2zwu73LFoitc/jxkay3bOysrRt2za99dZbevvttzVt2jTdd999OnDgQDS6nJTiaV8nlqOPOI4P8bqfE9OxIVLfMxF9o+zuwACHwxH02BgzqG649tfWh/qakRLudZs3b57mzZsXWL5gwQLdc889euWVV/TjH/84XN0eViS2b7y+Z8OJlfcsWiIRzxheKNt92rRpmjZtWuDx/Pnz1dHRoZdeekn33ntvRPuZzOJtXyeWo484jn3xvJ8T07EhVr7vYuRsH4n++te/rpSUlEG/vnR1dQ36lWaA2+0esv2oUaM0fvz4G7a53mtGQqTW7Vq33HKL5syZE7VRzZGslxXx+p6NRLTfs2iJ1j6PYOHab+fNm5dw+2Qsiad9nViOPuI4PsTrfk5Mx4Zofc9E5NmeRI8ZM0azZ89WU1NTUH1TU5MKCwuHfM78+fMHtW9sbFRBQYFGjx59wzbXe81IiNS6XcsYo8OHDysrKys8HR/GSNbLinh9z0Yi2u9ZtERrn0ewcO23bW1tCbdPxpJ42teJ5egjjuNDvO7nxHRsiNb3TERBVKcxu46Bqd5fe+01c+TIEVNZWWnGjRtnPv/8c2OMMWvWrDGPP/54oP3AlPvPPvusOXLkiHnttdcGTbn/q1/9yqSkpJiNGzeao0ePmo0bN9p6u6RwrpvH4zH79u0zv//9701bW5t58sknzahRo8w///M/x+x6GWNMW1ubaWtrM7NnzzZlZWWmra3NtLe3B5bH63tmZd1i4T2Llkjs8xheqNv97//+782ePXvM8ePHzW9/+1uzZs0aI8m89dZbdq1C3Onr6wvEviRTU1Nj2traArcpifd9nViOPuI4+hI9jq9GTMeGSHzPRPTFRBJtjDH/8A//YCZNmmTGjBlj7rnnHtPc3BxYtnz5clNUVBTUfv/+/WbWrFlmzJgxZvLkyaaurm7Qa/7jP/6jmTZtmhk9erSZPn26bQeVcK9bZWWlmThxohkzZoz5xje+YUpLS01LS0s0ViVIqOslaVCZNGlSUJt4fc+GW7dYec+iJRLxjOGFst03bdpk/uRP/sSMHTvW3HbbbWbhwoXmnXfesaHX8Wvg9kLXluXLlxtjEmNfJ5ajjziOrmSI46sR07EhEt+hEV0OY/59hgAAAAAAAHBDtl8TDQAAAABAvCCJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwCKSaAAAAAAALCKJBgAAAADAIpJoAAAAAAAsIokGAAAAAMAikmgAAAAAACwiiQYAAAAAwKL/D459AA3dXl2LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize = (12,6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(0,8): \n",
    "    axs[i].hist(best_test_preds[:,i,:])\n",
    "    ci = np.percentile(best_test_preds[:,i,:], q = (2.5, 97.5))\n",
    "    l, u = ci[0], ci[1]\n",
    "    axs[i].axvline(x=expit(catch_test_logits[cur_idx][i]), color = \"red\")\n",
    "    axs[i].axvline(x=l, color = \"green\")\n",
    "    axs[i].axvline(x=u, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce01e71c-1667-4491-8178-670a6dde0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   31.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   55.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  2.1min remaining:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  2.8min remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed:  3.1min remaining:   52.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed:  3.4min remaining:   22.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh achieved\n",
      "thresh achieved\n",
      "thresh achieved\n",
      "cutting off thresh achieved\n",
      "thresh achieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=15, verbose = 10, backend = \"loky\")(delayed(rep_one)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd5ade9f-4e51-4a7e-8a25-1734adf87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6e000d7-e363-4b6d-971a-ef2b7d2ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_coverage\", \"test_coverage\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb93357-a824-4974-8463-e0bbfa6114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = check[[\"exit_status\"]].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16218f38-25f3-4d63-b726-6bda3ced96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.columns = [\"exit_status\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f223facb-8e90-459b-98bd-4afb9588596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.to_csv(\"exit_status_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37dd034e-5c26-44a3-8ade-6767c4345c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449963/3676205243.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  check = check.drop([\"exit_status\"],1)\n"
     ]
    }
   ],
   "source": [
    "check = check.drop([\"exit_status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd86189c-c3c3-4c68-97ce-f5e7e4a30514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_coverage</th>\n",
       "      <th>test_coverage</th>\n",
       "      <th>avg_ci_width_train</th>\n",
       "      <th>avg_ci_width_test</th>\n",
       "      <th>avg_lstm_weight</th>\n",
       "      <th>exit_iter</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.290725</td>\n",
       "      <td>0.333095</td>\n",
       "      <td>0.586909</td>\n",
       "      <td>51</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.452344</td>\n",
       "      <td>0.438537</td>\n",
       "      <td>0.532321</td>\n",
       "      <td>231</td>\n",
       "      <td>1.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400053</td>\n",
       "      <td>0.453053</td>\n",
       "      <td>0.506688</td>\n",
       "      <td>107</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992741</td>\n",
       "      <td>0.991747</td>\n",
       "      <td>0.558175</td>\n",
       "      <td>40</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.781395</td>\n",
       "      <td>0.770795</td>\n",
       "      <td>0.549864</td>\n",
       "      <td>59</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.511211</td>\n",
       "      <td>5</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>0.550386</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>149</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.211749</td>\n",
       "      <td>0.252849</td>\n",
       "      <td>0.516437</td>\n",
       "      <td>109</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.138414</td>\n",
       "      <td>0.170667</td>\n",
       "      <td>0.515999</td>\n",
       "      <td>196</td>\n",
       "      <td>1.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.957225</td>\n",
       "      <td>0.969993</td>\n",
       "      <td>0.512564</td>\n",
       "      <td>150</td>\n",
       "      <td>1.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.090480</td>\n",
       "      <td>0.087335</td>\n",
       "      <td>0.564378</td>\n",
       "      <td>110</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.925377</td>\n",
       "      <td>0.908073</td>\n",
       "      <td>0.507841</td>\n",
       "      <td>47</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.925498</td>\n",
       "      <td>0.936886</td>\n",
       "      <td>0.519754</td>\n",
       "      <td>84</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.433140</td>\n",
       "      <td>0.462243</td>\n",
       "      <td>0.512592</td>\n",
       "      <td>125</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.137227</td>\n",
       "      <td>0.140268</td>\n",
       "      <td>0.517919</td>\n",
       "      <td>239</td>\n",
       "      <td>1.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.334292</td>\n",
       "      <td>0.345781</td>\n",
       "      <td>0.613446</td>\n",
       "      <td>70</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.282114</td>\n",
       "      <td>0.355656</td>\n",
       "      <td>0.616700</td>\n",
       "      <td>91</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.798175</td>\n",
       "      <td>0.799711</td>\n",
       "      <td>0.526713</td>\n",
       "      <td>172</td>\n",
       "      <td>1.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.869830</td>\n",
       "      <td>0.837303</td>\n",
       "      <td>0.516812</td>\n",
       "      <td>294</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.959199</td>\n",
       "      <td>0.965613</td>\n",
       "      <td>0.641626</td>\n",
       "      <td>66</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.972462</td>\n",
       "      <td>0.964231</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>204</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.142841</td>\n",
       "      <td>0.169216</td>\n",
       "      <td>0.513923</td>\n",
       "      <td>353</td>\n",
       "      <td>2.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.787213</td>\n",
       "      <td>0.872867</td>\n",
       "      <td>0.693823</td>\n",
       "      <td>24</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.970275</td>\n",
       "      <td>0.961657</td>\n",
       "      <td>0.506064</td>\n",
       "      <td>139</td>\n",
       "      <td>1.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.345577</td>\n",
       "      <td>0.360603</td>\n",
       "      <td>0.514002</td>\n",
       "      <td>285</td>\n",
       "      <td>1.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.140702</td>\n",
       "      <td>0.147083</td>\n",
       "      <td>0.511102</td>\n",
       "      <td>167</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.640348</td>\n",
       "      <td>0.633360</td>\n",
       "      <td>0.510590</td>\n",
       "      <td>245</td>\n",
       "      <td>1.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.387742</td>\n",
       "      <td>0.408495</td>\n",
       "      <td>0.585469</td>\n",
       "      <td>52</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.652393</td>\n",
       "      <td>0.759932</td>\n",
       "      <td>0.504164</td>\n",
       "      <td>300</td>\n",
       "      <td>1.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.177070</td>\n",
       "      <td>0.228064</td>\n",
       "      <td>0.510333</td>\n",
       "      <td>229</td>\n",
       "      <td>1.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.958138</td>\n",
       "      <td>0.942978</td>\n",
       "      <td>0.518454</td>\n",
       "      <td>111</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.189523</td>\n",
       "      <td>0.178095</td>\n",
       "      <td>0.531656</td>\n",
       "      <td>383</td>\n",
       "      <td>2.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.717912</td>\n",
       "      <td>0.740433</td>\n",
       "      <td>0.608697</td>\n",
       "      <td>79</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.689282</td>\n",
       "      <td>0.719992</td>\n",
       "      <td>0.581380</td>\n",
       "      <td>71</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.581937</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.500954</td>\n",
       "      <td>27</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.325384</td>\n",
       "      <td>0.340801</td>\n",
       "      <td>0.526176</td>\n",
       "      <td>184</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.116486</td>\n",
       "      <td>0.139477</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>155</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.588905</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.535119</td>\n",
       "      <td>147</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.314001</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>0.698048</td>\n",
       "      <td>33</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.157954</td>\n",
       "      <td>0.158418</td>\n",
       "      <td>0.544246</td>\n",
       "      <td>170</td>\n",
       "      <td>1.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.237514</td>\n",
       "      <td>0.265894</td>\n",
       "      <td>0.503720</td>\n",
       "      <td>131</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.189855</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>0.526341</td>\n",
       "      <td>232</td>\n",
       "      <td>1.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.126396</td>\n",
       "      <td>0.533974</td>\n",
       "      <td>176</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.203852</td>\n",
       "      <td>0.208385</td>\n",
       "      <td>0.594432</td>\n",
       "      <td>52</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.360446</td>\n",
       "      <td>0.353839</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>225</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.176254</td>\n",
       "      <td>0.189777</td>\n",
       "      <td>0.563265</td>\n",
       "      <td>74</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>0.997762</td>\n",
       "      <td>0.470932</td>\n",
       "      <td>168</td>\n",
       "      <td>1.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.169602</td>\n",
       "      <td>0.220503</td>\n",
       "      <td>0.527877</td>\n",
       "      <td>91</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.675858</td>\n",
       "      <td>0.718874</td>\n",
       "      <td>0.653938</td>\n",
       "      <td>43</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996091</td>\n",
       "      <td>0.994876</td>\n",
       "      <td>0.445758</td>\n",
       "      <td>42</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_coverage  test_coverage  avg_ci_width_train  avg_ci_width_test  \\\n",
       "0         0.954545          0.750            0.290725           0.333095   \n",
       "1         0.954545          1.000            0.452344           0.438537   \n",
       "2         0.954545          1.000            0.400053           0.453053   \n",
       "3         1.000000          1.000            0.992741           0.991747   \n",
       "4         0.984848          1.000            0.781395           0.770795   \n",
       "5         1.000000          1.000            0.999998           0.999999   \n",
       "6         0.984848          0.875            0.533422           0.550386   \n",
       "7         0.969697          1.000            0.211749           0.252849   \n",
       "8         0.954545          0.750            0.138414           0.170667   \n",
       "9         0.984848          1.000            0.957225           0.969993   \n",
       "10        0.969697          0.875            0.090480           0.087335   \n",
       "11        0.954545          0.750            0.925377           0.908073   \n",
       "12        0.984848          1.000            0.925498           0.936886   \n",
       "13        0.984848          1.000            0.433140           0.462243   \n",
       "14        0.954545          0.750            0.137227           0.140268   \n",
       "15        0.954545          1.000            0.334292           0.345781   \n",
       "16        0.969697          0.875            0.282114           0.355656   \n",
       "17        0.984848          1.000            0.798175           0.799711   \n",
       "18        1.000000          1.000            0.869830           0.837303   \n",
       "19        0.954545          0.875            0.959199           0.965613   \n",
       "20        1.000000          1.000            0.972462           0.964231   \n",
       "21        1.000000          0.875            0.142841           0.169216   \n",
       "22        0.969697          1.000            0.787213           0.872867   \n",
       "23        1.000000          1.000            0.970275           0.961657   \n",
       "24        0.954545          0.875            0.345577           0.360603   \n",
       "25        0.954545          0.625            0.140702           0.147083   \n",
       "26        0.984848          0.875            0.640348           0.633360   \n",
       "27        0.954545          0.875            0.387742           0.408495   \n",
       "28        0.954545          1.000            0.652393           0.759932   \n",
       "29        0.954545          0.750            0.177070           0.228064   \n",
       "30        0.954545          1.000            0.958138           0.942978   \n",
       "31        0.954545          1.000            0.189523           0.178095   \n",
       "32        0.954545          1.000            0.717912           0.740433   \n",
       "33        0.954545          1.000            0.689282           0.719992   \n",
       "34        0.954545          1.000            0.581937           0.626070   \n",
       "35        0.954545          0.875            0.325384           0.340801   \n",
       "36        0.954545          1.000            0.116486           0.139477   \n",
       "37        0.969697          1.000            0.588905           0.573072   \n",
       "38        0.969697          1.000            0.314001           0.303478   \n",
       "39        0.954545          1.000            0.157954           0.158418   \n",
       "40        0.954545          0.875            0.237514           0.265894   \n",
       "41        0.954545          0.625            0.189855           0.197294   \n",
       "42        0.969697          0.750            0.090670           0.126396   \n",
       "43        0.954545          0.750            0.203852           0.208385   \n",
       "44        0.954545          1.000            0.360446           0.353839   \n",
       "45        0.969697          0.875            0.176254           0.189777   \n",
       "46        1.000000          1.000            0.998693           0.997762   \n",
       "47        0.954545          1.000            0.169602           0.220503   \n",
       "48        0.954545          1.000            0.675858           0.718874   \n",
       "49        1.000000          1.000            0.996091           0.994876   \n",
       "\n",
       "    avg_lstm_weight  exit_iter  time_taken  \n",
       "0          0.586909         51    0.450000  \n",
       "1          0.532321        231    1.616667  \n",
       "2          0.506688        107    0.683333  \n",
       "3          0.558175         40    0.450000  \n",
       "4          0.549864         59    0.500000  \n",
       "5          0.511211          5    0.366667  \n",
       "6          0.568008        149    0.833333  \n",
       "7          0.516437        109    0.833333  \n",
       "8          0.515999        196    1.383333  \n",
       "9          0.512564        150    1.116667  \n",
       "10         0.564378        110    0.766667  \n",
       "11         0.507841         47    0.433333  \n",
       "12         0.519754         84    0.683333  \n",
       "13         0.512592        125    0.833333  \n",
       "14         0.517919        239    1.650000  \n",
       "15         0.613446         70    0.583333  \n",
       "16         0.616700         91    0.633333  \n",
       "17         0.526713        172    1.433333  \n",
       "18         0.516812        294    2.250000  \n",
       "19         0.641626         66    0.566667  \n",
       "20         0.563910        204    1.333333  \n",
       "21         0.513923        353    2.416667  \n",
       "22         0.693823         24    0.216667  \n",
       "23         0.506064        139    1.016667  \n",
       "24         0.514002        285    1.983333  \n",
       "25         0.511102        167    1.000000  \n",
       "26         0.510590        245    1.716667  \n",
       "27         0.585469         52    0.450000  \n",
       "28         0.504164        300    1.616667  \n",
       "29         0.510333        229    1.566667  \n",
       "30         0.518454        111    0.866667  \n",
       "31         0.531656        383    2.466667  \n",
       "32         0.608697         79    0.483333  \n",
       "33         0.581380         71    0.583333  \n",
       "34         0.500954         27    0.300000  \n",
       "35         0.526176        184    1.066667  \n",
       "36         0.502462        155    0.916667  \n",
       "37         0.535119        147    1.050000  \n",
       "38         0.698048         33    0.333333  \n",
       "39         0.544246        170    1.183333  \n",
       "40         0.503720        131    0.966667  \n",
       "41         0.526341        232    1.266667  \n",
       "42         0.533974        176    1.200000  \n",
       "43         0.594432         52    0.400000  \n",
       "44         0.571843        225    1.400000  \n",
       "45         0.563265         74    0.583333  \n",
       "46         0.470932        168    1.183333  \n",
       "47         0.527877         91    0.550000  \n",
       "48         0.653938         43    0.333333  \n",
       "49         0.445758         42    0.433333  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "441c567f-ba58-47ea-a834-5b0050e42999",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f57649fb-845d-47df-9a49-ae51d03094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f0f4c8-ca34-4103-9ff3-e4cb81275e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"mean_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens) +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31547d49-11f1-4b34-a8de-433017af2416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_coverage</td>\n",
       "      <td>0.968485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_coverage</td>\n",
       "      <td>0.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_ci_width_train</td>\n",
       "      <td>0.509368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_ci_width_test</td>\n",
       "      <td>0.525438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_lstm_weight</td>\n",
       "      <td>0.544972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit_iter</td>\n",
       "      <td>139.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_taken</td>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics       value\n",
       "0      train_coverage    0.968485\n",
       "1       test_coverage    0.922500\n",
       "2  avg_ci_width_train    0.509368\n",
       "3   avg_ci_width_test    0.525438\n",
       "4     avg_lstm_weight    0.544972\n",
       "5           exit_iter  139.740000\n",
       "6          time_taken    0.979000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2da43887-bc95-4916-bca8-64efbca5d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median = check.median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358af176-915a-4b97-b36f-7e700d319dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105892c9-0e07-497b-81bf-13bea38dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_median.to_csv(\"median_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a2b9ecc-4c6f-4536-b045-dfb1b91bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a89143b-116c-46e7-9d86-89989b661f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be839ff8-5c13-4237-8e0a-c365cb12b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.columns = [\"metrics\", \"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38954c2e-632b-46b5-9ba8-21e2be380444",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"std_dev_metrics_EnKF_LSTM_Doc2Vec_\" + \"var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)+  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04c9db91-d575-4ed5-9a15-75806b53fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/np.sqrt(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "#     catch_1 = []\n",
    "#     catch_2 = []\n",
    "#     catch_3 = []\n",
    "#     catch_4 = []\n",
    "#     catch_5 = []\n",
    "# #     from scipy.special import expit\n",
    "#     patience_smaller = 0\n",
    "# # patience_bigger = 0\n",
    "\n",
    "# #     best_train_acc = 0\n",
    "# #     best_valid_acc = 1000\n",
    "\n",
    "# #     best_valid_mae = 10\n",
    "    \n",
    "#     best_train_mae = 100\n",
    "    \n",
    "#     X_train_logits = np.vstack((catch1[idx][0], catch1[idx][1]))\n",
    "# #     X_train_logits = catch_train_logits_second[idx]\n",
    "\n",
    "#     ## create training batch chunks\n",
    "#     train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "#     batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "#     ## generate some augmented variable for iteration 0\n",
    "#     initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "#     initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "#     initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "#     initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    \n",
    "#     log_sigma_points_1 = (np.log(gamma(100, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "# #     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "# #     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "# #     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "#     train_lstm = catch1[idx][3].numpy()\n",
    "#     valid_lstm = catch1[idx][4].numpy()\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_lstm = catch1[idx][5].numpy()\n",
    " \n",
    "\n",
    "#     train_doc2vec = catch[idx][6].values\n",
    "#     valid_doc2vec = catch[idx][7].values\n",
    "#     # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "#     test_doc2vec = catch[idx][8].values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "#     train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "#     train_valid_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "#     train_valid_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "\n",
    "#     # best_width_train = 100\n",
    "    \n",
    "#     # threshold_achieved = False\n",
    "#     # satisfactory = False\n",
    "#     # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "#     best_coverage_train = 0\n",
    "    \n",
    "#     for iter1 in range(0,500):\n",
    "\n",
    "#         for batch_idx in batch_chunks:\n",
    "\n",
    "#             batch_data = train_valid_test_lstm[batch_idx,:]\n",
    "#             batch_data1 = train_valid_test_doc2vec[batch_idx,:]\n",
    "#             # print(batch_data.shape)\n",
    "#             batch_targets = X_train_logits[batch_idx,:]\n",
    "#             # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "#             column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "#             H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "#             current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "#             var_targets_vec = var_targets_vec\n",
    "            \n",
    "#             # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "#             current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "#             G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "#             scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "#             temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "#             temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "#             for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "#                 var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "#                 R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "#                 measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "#                 target_current = batch_targets + measurement_error\n",
    "                \n",
    "#                 K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "\n",
    "#                 current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "#             weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "#             weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "#             initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "#             log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "#             avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "#             complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_valid_lstm, train_valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, train_valid_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# #             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "#             initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "#             initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "#             initial_targets_train_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width_train = np.mean(width)\n",
    "            \n",
    "#             interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "            \n",
    "# #             ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "# #             coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "#             train_mae = np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel()))\n",
    "        \n",
    "#             current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#             initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#             initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "#             initial_targets_test = initial_targets\n",
    "            \n",
    "#             initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "# #             li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# #             ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# #             width = ui - li\n",
    "            \n",
    "# #             avg_width = np.mean(width)\n",
    "            \n",
    "# #             ind_test = (catch_test_probs[idx] >= li) & (catch_test_probs[idx] <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "# #             coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "#             # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "#             test_mae = np.mean(np.abs(catch_test_probs[idx].ravel() - initial_targets_test_mean.ravel()))\n",
    "       \n",
    "#         # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         # print(\"epoch \"+ str(iter1))\n",
    "#         # print(\"patience \"+ str(patience_smaller))\n",
    "#         # print(\"train mae is \" + str(train_mae))\n",
    "#         # print(\"test mae is \" + str(test_mae))\n",
    "\n",
    "#         # print(\"train width is \" + str(avg_width_train))        \n",
    "#         # print(\"test coverage is \"+ str(coverage_test))\n",
    "#         # print(\"test width is \" + str(avg_width))\n",
    "#         # print(\"lstm weight is \" + str(np.mean(complement)))\n",
    "#         # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "    \n",
    "#         if (train_mae < best_train_mae) : \n",
    "# #             cur_best_train_width = avg_width_train\n",
    "# #             cur_best_test_width = avg_width\n",
    "\n",
    "# #             cur_best_train_coverage = coverage_train\n",
    "# #             cur_best_test_coverage = coverage_test \n",
    "# #             cur_best_lstm_weight = np.mean(complement)\n",
    "#             best_train_mae = train_mae\n",
    "#             best_test_mae = test_mae\n",
    "#             exit_iter_no_thresh = iter1\n",
    "#             best_test_preds = initial_targets_test_mean\n",
    "#             patience_smaller = 0\n",
    "#             # satisfactory = True\n",
    "            \n",
    "#         else:\n",
    "#             patience_smaller+=1\n",
    "            \n",
    "#         if patience_smaller > threshold:\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#         if (patience_smaller > cutoff_threshold) & (train_mae < 0.05):\n",
    "            \n",
    "#             break\n",
    "            \n",
    "            \n",
    "#     print(best_test_mae, flush = True)\n",
    "#     return best_train_mae, best_test_mae, exit_iter_no_thresh, best_test_preds\n",
    "        \n",
    "#     # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99aaf7b8-7702-4849-b774-601be147e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one_real_world(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = Parallel(n_jobs=use_cores, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\",  \"exit_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.std()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     # all_preds = all_preds.mean(0)\n",
    "#     true_probs = catch_test_probs[i].ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"enkf preds\")\n",
    "# plt.ylabel(\"lstm preds\")\n",
    "# plt.axline((0, 0), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
